{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "(more sample_5_enc)attack sequence prediction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBHs11WJ5etB",
        "outputId": "40d60413-6bcd-4a1e-98de-c8f9b8ab48a1"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Mar 10 16:39:15 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.56       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   55C    P8    11W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYb9slpME7UX"
      },
      "source": [
        "# Experiment 3\n",
        "\n",
        "Now, we'll take a different approach which will result in increased number of samples. We'll use a *'sliding window'* technique that will slide over the samples and partition the sample into encoder and decoder data.\n",
        "\n",
        "For example, if `sliding_window=4` then for a sample of length=25, first 4 timesteps will go to encoder_data and rest would be decoder_data. The window will then slide, lets say 1 timestep to the right, making timesteps 2-5 the encoder data and rest as decoder_data. This way, the sliding window will be shifted through the entire sample until it touches the threshold for minimum decoder_data_length.\n",
        "\n",
        "By designing the samples in this way, we hope to better capture the relationship between the attack steps and thus increasing the accuracy of prediction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhtGZ6-YEiai",
        "outputId": "b5c8a87b-9c5c-4c91-a686-2f6068bff830"
      },
      "source": [
        "# mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjbZly4CE4IQ",
        "outputId": "b537eadb-9862-4317-de95-3ad40b0e2583"
      },
      "source": [
        "%cd /content/drive/MyDrive/Thesis/Attack\\ Step\\ Prediction/Implementation"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Thesis/Attack Step Prediction/Implementation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXh8F5TkE5Gn"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import random\n",
        "import csv\n",
        "\n",
        "import aptgen_utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qrztRtpep29"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJFeeZycE-gq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dc341b6-d563-4a48-e398-77082e871c30"
      },
      "source": [
        "# to reflect the changes, the module needs to be reloaded\n",
        "import importlib\n",
        "importlib.reload(aptgen_utils)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'aptgen_utils' from '/content/drive/MyDrive/Thesis/Attack Step Prediction/Implementation/aptgen_utils.py'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZcEVBrsIVtK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc20d5b3-77a8-4621-c1e9-b87597913e74"
      },
      "source": [
        "# get attack sequences as list of lists\n",
        "data_text = aptgen_utils.get_data_text()\n",
        "print(data_text[0])\n",
        "len(data_text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['collection TA0009 Email_Collection T1114', 'credential_access TA0006 Credential_Dumping T1003', 'discovery TA0007 System_Information_Discovery T1082', 'collection TA0009 Email_Collection T1114', 'defense_evasion TA0005 File_Deletion T1107', 'persistence TA0003 Scheduled_Task T1053', 'discovery TA0007 System_Information_Discovery T1082', 'collection TA0009 Email_Collection T1114']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "800"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JKQkR8OIkfi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bab407d3-5497-4a9c-90cc-9e2588742f06"
      },
      "source": [
        "# strip all spaces from data_text\n",
        "data_text = [[''.join(''.join(step).split()) for step in data] for data in data_text]\n",
        "print(data_text[0])\n",
        "len(data_text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['collectionTA0009Email_CollectionT1114', 'credential_accessTA0006Credential_DumpingT1003', 'discoveryTA0007System_Information_DiscoveryT1082', 'collectionTA0009Email_CollectionT1114', 'defense_evasionTA0005File_DeletionT1107', 'persistenceTA0003Scheduled_TaskT1053', 'discoveryTA0007System_Information_DiscoveryT1082', 'collectionTA0009Email_CollectionT1114']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "800"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbWAeRjUJY12"
      },
      "source": [
        "Lets look at the sequence lengths in the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reO2icHjJETc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39329b03-f774-4ac1-d474-a15296b12f9c"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "# get length of different sequences in a list\n",
        "sequence_lengths = [len(sequence) for sequence in data_text]\n",
        "\n",
        "counter = Counter(sequence_lengths)\n",
        "print(\"Frequncy of sequence lengths:\", counter)\n",
        "print(\"Number of unique sequence lengths:\", len(counter.keys()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Frequncy of sequence lengths: Counter({8: 117, 6: 62, 14: 56, 12: 49, 15: 45, 9: 44, 16: 42, 7: 39, 13: 37, 11: 32, 18: 30, 5: 29, 10: 29, 17: 28, 22: 23, 19: 19, 21: 18, 25: 14, 20: 10, 27: 9, 28: 9, 24: 8, 29: 8, 26: 7, 30: 7, 32: 7, 23: 6, 4: 5, 33: 4, 31: 3, 34: 3, 35: 1})\n",
            "Number of unique sequence lengths: 32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MbUFlLZJeZS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bba5198-dfa1-4ae1-a6db-da2ec6106cde"
      },
      "source": [
        "counter"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({4: 5,\n",
              "         5: 29,\n",
              "         6: 62,\n",
              "         7: 39,\n",
              "         8: 117,\n",
              "         9: 44,\n",
              "         10: 29,\n",
              "         11: 32,\n",
              "         12: 49,\n",
              "         13: 37,\n",
              "         14: 56,\n",
              "         15: 45,\n",
              "         16: 42,\n",
              "         17: 28,\n",
              "         18: 30,\n",
              "         19: 19,\n",
              "         20: 10,\n",
              "         21: 18,\n",
              "         22: 23,\n",
              "         23: 6,\n",
              "         24: 8,\n",
              "         25: 14,\n",
              "         26: 7,\n",
              "         27: 9,\n",
              "         28: 9,\n",
              "         29: 8,\n",
              "         30: 7,\n",
              "         31: 3,\n",
              "         32: 7,\n",
              "         33: 4,\n",
              "         34: 3,\n",
              "         35: 1})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WF0-JGaMIz8K"
      },
      "source": [
        "We'll work with a sliding window of 4 to start with, so all samples with length 4 will be removed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7VmGa2hJof5"
      },
      "source": [
        "def remove_sequence(data_text, lengths_to_remove):\n",
        "    lengths_to_remove = lengths_to_remove\n",
        "    truncated_data_text = [sequence for sequence in data_text if len(sequence) not in lengths_to_remove]\n",
        "    print(\"First sequence after truncating:\", truncated_data_text[0])\n",
        "    print(\"Number of sequence after truncating:\", len(truncated_data_text))\n",
        "\n",
        "    return truncated_data_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dq_i6IkJpuP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fba40937-8ce7-4f9a-8b89-7c5395c3e327"
      },
      "source": [
        "# remove sequences having length 4\n",
        "lengths_to_remove = [4]\n",
        "truncated_data_text = remove_sequence(data_text, lengths_to_remove)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First sequence after truncating: ['collectionTA0009Email_CollectionT1114', 'credential_accessTA0006Credential_DumpingT1003', 'discoveryTA0007System_Information_DiscoveryT1082', 'collectionTA0009Email_CollectionT1114', 'defense_evasionTA0005File_DeletionT1107', 'persistenceTA0003Scheduled_TaskT1053', 'discoveryTA0007System_Information_DiscoveryT1082', 'collectionTA0009Email_CollectionT1114']\n",
            "Number of sequence after truncating: 795\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FtwSAmrLPhl"
      },
      "source": [
        "def get_encoder_decoder_text(text, sliding_window_size, shift_right, min_decoder_length):\n",
        "    encoder_text, decoder_text = [], []\n",
        "\n",
        "    for sequence in text:\n",
        "        # the window will slide 'shift_right' positions at each iteration\n",
        "        for i in range(0, len(sequence) - sliding_window_size, shift_right):\n",
        "            # break if decoder_text length exceeds min_decoder_length\n",
        "            if i+sliding_window_size+min_decoder_length > len(sequence):\n",
        "                break\n",
        "\n",
        "            encoder_text.append(sequence[i:i+sliding_window_size])\n",
        "            decoder_text.append(sequence[i+sliding_window_size:])\n",
        "\n",
        "    return encoder_text, decoder_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itAlysw6StqZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88d9a101-e63f-4ff3-f473-a3e84fbd3efd"
      },
      "source": [
        "sliding_window_size = 5\n",
        "shift_right = 1\n",
        "min_decoder_length = 1\n",
        "\n",
        "encoder_text, decoder_text = get_encoder_decoder_text(truncated_data_text, sliding_window_size, shift_right, min_decoder_length)\n",
        "print(\"Number of samples:\", len(encoder_text))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of samples: 6835\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3ii18QkNsGi"
      },
      "source": [
        "def append_sos_eos(decoder_text):    \n",
        "    decoder_input_text, decoder_target_text = [], []\n",
        "\n",
        "    for sequence in decoder_text:\n",
        "        decoder_input_text.append([\"<sos>\"] + sequence[:])\n",
        "        decoder_target_text.append(sequence[:] + [\"<eos>\"])\n",
        "\n",
        "    return decoder_input_text, decoder_target_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTRkjvByUW0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce8524fe-470d-441a-bf6b-561ded0f1745"
      },
      "source": [
        "import copy\n",
        "encoder_input_text = copy.deepcopy(encoder_text)\n",
        "decoder_input_text, decoder_target_text = append_sos_eos(decoder_text)\n",
        "\n",
        "print(\"encoder_input_text[0]:\", encoder_input_text[0], \"\\ndecoder_input_text[0]:\", decoder_input_text[0], \"\\ndecoder_target_text[0]:\", decoder_target_text[0], \"\\n\")\n",
        "print(\"encoder_input_text[69]:\", encoder_input_text[69], \"\\ndecoder_input_text[69]:\", decoder_input_text[69], \"\\ndecoder_target_text[69]:\", decoder_target_text[69], \"\\n\")\n",
        "print(\"encoder_input_text[169]:\", encoder_input_text[169], \"\\ndecoder_input_text[169]:\", decoder_input_text[169], \"\\ndecoder_target_text[169]:\", decoder_target_text[169], \"\\n\")\n",
        "print(\"encoder_input_text[650]:\", encoder_input_text[650], \"\\ndecoder_input_text[650]:\", decoder_input_text[650], \"\\ndecoder_target_text[650]:\", decoder_target_text[650], \"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "encoder_input_text[0]: ['collectionTA0009Email_CollectionT1114', 'credential_accessTA0006Credential_DumpingT1003', 'discoveryTA0007System_Information_DiscoveryT1082', 'collectionTA0009Email_CollectionT1114', 'defense_evasionTA0005File_DeletionT1107'] \n",
            "decoder_input_text[0]: ['<sos>', 'persistenceTA0003Scheduled_TaskT1053', 'discoveryTA0007System_Information_DiscoveryT1082', 'collectionTA0009Email_CollectionT1114'] \n",
            "decoder_target_text[0]: ['persistenceTA0003Scheduled_TaskT1053', 'discoveryTA0007System_Information_DiscoveryT1082', 'collectionTA0009Email_CollectionT1114', '<eos>'] \n",
            "\n",
            "encoder_input_text[69]: ['discoveryTA0007Permission_Groups_DiscoveryT1069', 'defense_evasionTA0005File_DeletionT1107', 'persistenceTA0003Scheduled_TaskT1053', 'discoveryTA0007System_Information_DiscoveryT1082', 'discoveryTA0007Permission_Groups_DiscoveryT1069'] \n",
            "decoder_input_text[69]: ['<sos>', 'discoveryTA0007Remote_System_DiscoveryT1018', 'collectionTA0009Data_StagedT1074', 'lateral_movementTA0008Pass_the_HashT1075'] \n",
            "decoder_target_text[69]: ['discoveryTA0007Remote_System_DiscoveryT1018', 'collectionTA0009Data_StagedT1074', 'lateral_movementTA0008Pass_the_HashT1075', '<eos>'] \n",
            "\n",
            "encoder_input_text[169]: ['collectionTA0009Data_StagedT1074', 'credential_accessTA0006Credential_DumpingT1003', 'collectionTA0009Data_StagedT1074', 'credential_accessTA0006Credentials_in_RegistryT1214', 'discoveryTA0007System_Information_DiscoveryT1082'] \n",
            "decoder_input_text[169]: ['<sos>', 'defense_evasionTA0005File_DeletionT1107', 'discoveryTA0007Remote_System_DiscoveryT1018', 'discoveryTA0007Permission_Groups_DiscoveryT1069', 'defense_evasionTA0005File_DeletionT1107', 'lateral_movementTA0008Pass_the_HashT1075'] \n",
            "decoder_target_text[169]: ['defense_evasionTA0005File_DeletionT1107', 'discoveryTA0007Remote_System_DiscoveryT1018', 'discoveryTA0007Permission_Groups_DiscoveryT1069', 'defense_evasionTA0005File_DeletionT1107', 'lateral_movementTA0008Pass_the_HashT1075', '<eos>'] \n",
            "\n",
            "encoder_input_text[650]: ['credential_accessTA0006Credential_DumpingT1003', 'collectionTA0009Email_CollectionT1114', 'discoveryTA0007Remote_System_DiscoveryT1018', 'credential_accessTA0006Credentials_in_RegistryT1214', 'collectionTA0009Data_StagedT1074'] \n",
            "decoder_input_text[650]: ['<sos>', 'discoveryTA0007System_Network_Configuration_DiscoveryT1016', 'collectionTA0009Email_CollectionT1114', 'lateral_movementTA0008Pass_the_HashT1075', 'collectionTA0009Email_CollectionT1114', 'exfiltrationTA0010Exfiltration_Over_Command_and_Control_ChannelT1041', 'defense_evasionTA0005File_DeletionT1107'] \n",
            "decoder_target_text[650]: ['discoveryTA0007System_Network_Configuration_DiscoveryT1016', 'collectionTA0009Email_CollectionT1114', 'lateral_movementTA0008Pass_the_HashT1075', 'collectionTA0009Email_CollectionT1114', 'exfiltrationTA0010Exfiltration_Over_Command_and_Control_ChannelT1041', 'defense_evasionTA0005File_DeletionT1107', '<eos>'] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDMMf-P1XxkW"
      },
      "source": [
        "# Text sequences to integer sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSEJOAo2VeN1"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "def get_tokenizer(text):\n",
        "    tokenizer = Tokenizer(num_words=200, lower=False) # we just give a large enough arbitrary number\n",
        "    tokenizer.fit_on_texts(text)\n",
        "    \n",
        "    # builid word2idx and idx2word dictionary\n",
        "    word2idx = copy.deepcopy(tokenizer.word_index)\n",
        "    idx2word = {v:k for k, v in tokenizer.word_index.items()}\n",
        "\n",
        "    return tokenizer, word2idx, idx2word"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7Z42oJwVj_h"
      },
      "source": [
        "def get_encoder_decoder_indices(encoder_input_text, decoder_input_text, decoder_target_text):\n",
        "    encoder_tokenizer, encoder_word2idx, encoder_idx2word = get_tokenizer(encoder_input_text)\n",
        "    print(\"encoder_word2idx:\", encoder_word2idx)\n",
        "    print(\"encoder_idx2word:\", encoder_idx2word)\n",
        "    encoder_input_indices = encoder_tokenizer.texts_to_sequences(encoder_input_text)\n",
        "\n",
        "\n",
        "    decoder_tokenizer, decoder_word2idx, decoder_idx2word = get_tokenizer(decoder_input_text + decoder_target_text)\n",
        "    print(\"\\ndecoder_word2idx:\", decoder_word2idx)\n",
        "    print(\"decoder_idx2word:\", decoder_idx2word)\n",
        "    decoder_input_indices = decoder_tokenizer.texts_to_sequences(decoder_input_text)\n",
        "    decoder_target_indices = decoder_tokenizer.texts_to_sequences(decoder_target_text)\n",
        "\n",
        "    print(\"\\nencoder_input_indices[0]:\", encoder_input_indices[0], \"\\ndecoder_input_indices[0]:\", decoder_input_indices[0], \"\\ndecoder_target_indices[0]:\", decoder_target_indices[0], \"\\n\")\n",
        "    print(\"encoder_input_indices[69]:\", encoder_input_indices[69], \"\\ndecoder_input_indices[69]:\", decoder_input_indices[69], \"\\ndecoder_target_indices[69]:\", decoder_target_indices[69], \"\\n\")\n",
        "    print(\"encoder_input_indices[169]:\", encoder_input_indices[169], \"\\ndecoder_input_indices[169]:\", decoder_input_indices[169], \"\\ndecoder_target_indices[169]:\", decoder_target_indices[169], \"\\n\")\n",
        "    print(\"encoder_input_indices[650]:\", encoder_input_indices[650], \"\\ndecoder_input_indices[650]:\", decoder_input_indices[650], \"\\ndecoder_target_indices[650]:\", decoder_target_indices[650], \"\\n\")\n",
        "\n",
        "    return encoder_input_indices, decoder_input_indices, decoder_target_indices, encoder_word2idx, encoder_idx2word, decoder_word2idx, decoder_idx2word"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bg2ocuO9VmQ1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97ba7771-d2ce-4239-d893-1b1790d031ef"
      },
      "source": [
        "# get input_indices and word conversion dicts\n",
        "encoder_input_indices, decoder_input_indices, decoder_target_indices, encoder_word2idx, encoder_idx2word, decoder_word2idx, decoder_idx2word \\\n",
        "= \\\n",
        "get_encoder_decoder_indices(encoder_input_text, decoder_input_text, decoder_target_text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "encoder_word2idx: {'credential_accessTA0006Credential_DumpingT1003': 1, 'discoveryTA0007File_and_Directory_DiscoveryT1083': 2, 'collectionTA0009Data_StagedT1074': 3, 'defense_evasionTA0005File_DeletionT1107': 4, 'discoveryTA0007Remote_System_DiscoveryT1018': 5, 'defense_evasionTA0005Deobfuscate/Decode_Files_or_InformationT1140': 6, 'lateral_movementTA0008Remote_File_CopyT1105': 7, 'exfiltrationTA0010Exfiltration_Over_Command_and_Control_ChannelT1041': 8, 'collectionTA0009Email_CollectionT1114': 9, 'collectionTA0009Input_CaptureT1056': 10, 'discoveryTA0007System_Time_DiscoveryT1124': 11, 'credential_accessTA0006Credentials_in_FilesT1081': 12, 'defense_evasionTA0005Indicator_Removal_on_HostT1070': 13, 'credential_accessTA0006Input_CaptureT1056': 14, 'persistenceTA0003New_ServiceT1050': 15, 'credential_accessTA0006Credentials_in_RegistryT1214': 16, 'lateral_movementTA0008Remote_Desktop_ProtocolT1076': 17, 'persistenceTA0003Scheduled_TaskT1053': 18, 'discoveryTA0007Account_DiscoveryT1087': 19, 'discoveryTA0007System_Network_Configuration_DiscoveryT1016': 20, 'discoveryTA0007Query_RegistryT1012': 21, 'discoveryTA0007System_Service_DiscoveryT1007': 22, 'discoveryTA0007Network_Share_DiscoveryT1135': 23, 'discoveryTA0007System_Information_DiscoveryT1082': 24, 'defense_evasionTA0005Image_File_Execution_Options_InjectionT1183': 25, 'defense_evasionTA0005Component_Object_Model_HijackingT1122': 26, 'credential_accessTA0006Brute_ForceT1110': 27, 'discoveryTA0007Security_Software_DiscoveryT1063': 28, 'defense_evasionTA0005MasqueradingT1036': 29, 'lateral_movementTA0008Pass_the_HashT1075': 30, 'persistenceTA0003Winlogon_Helper_DLLT1004': 31, 'discoveryTA0007Password_Policy_DiscoveryT1201': 32, 'persistenceTA0003Windows_Management_Instrumentation_Event_SubscriptionT1084': 33, 'exfiltrationTA0010Data_EncryptedT1022': 34, 'persistenceTA0003Registry_Run_Keys_/_Startup_FolderT1060': 35, 'discoveryTA0007System_Network_Connections_DiscoveryT1049': 36, 'persistenceTA0003Logon_ScriptsT1037': 37, 'persistenceTA0003Component_Object_Model_HijackingT1122': 38, 'persistenceTA0003Image_File_Execution_Options_InjectionT1183': 39, 'lateral_movementTA0008Logon_ScriptsT1037': 40, 'lateral_movementTA0008Windows_Remote_ManagementT1028': 41, 'discoveryTA0007Permission_Groups_DiscoveryT1069': 42, 'persistenceTA0003AppInit_DLLsT1103': 43, 'exfiltrationTA0010Data_CompressedT1002': 44, 'credential_accessTA0006HookingT1179': 45, 'discoveryTA0007System_Owner/User_DiscoveryT1033': 46, 'persistenceTA0003HookingT1179': 47, 'persistenceTA0003Security_Support_ProviderT1101': 48, 'persistenceTA0003Netsh_Helper_DLLT1128': 49, 'persistenceTA0003Accessibility_FeaturesT1015': 50}\n",
            "encoder_idx2word: {1: 'credential_accessTA0006Credential_DumpingT1003', 2: 'discoveryTA0007File_and_Directory_DiscoveryT1083', 3: 'collectionTA0009Data_StagedT1074', 4: 'defense_evasionTA0005File_DeletionT1107', 5: 'discoveryTA0007Remote_System_DiscoveryT1018', 6: 'defense_evasionTA0005Deobfuscate/Decode_Files_or_InformationT1140', 7: 'lateral_movementTA0008Remote_File_CopyT1105', 8: 'exfiltrationTA0010Exfiltration_Over_Command_and_Control_ChannelT1041', 9: 'collectionTA0009Email_CollectionT1114', 10: 'collectionTA0009Input_CaptureT1056', 11: 'discoveryTA0007System_Time_DiscoveryT1124', 12: 'credential_accessTA0006Credentials_in_FilesT1081', 13: 'defense_evasionTA0005Indicator_Removal_on_HostT1070', 14: 'credential_accessTA0006Input_CaptureT1056', 15: 'persistenceTA0003New_ServiceT1050', 16: 'credential_accessTA0006Credentials_in_RegistryT1214', 17: 'lateral_movementTA0008Remote_Desktop_ProtocolT1076', 18: 'persistenceTA0003Scheduled_TaskT1053', 19: 'discoveryTA0007Account_DiscoveryT1087', 20: 'discoveryTA0007System_Network_Configuration_DiscoveryT1016', 21: 'discoveryTA0007Query_RegistryT1012', 22: 'discoveryTA0007System_Service_DiscoveryT1007', 23: 'discoveryTA0007Network_Share_DiscoveryT1135', 24: 'discoveryTA0007System_Information_DiscoveryT1082', 25: 'defense_evasionTA0005Image_File_Execution_Options_InjectionT1183', 26: 'defense_evasionTA0005Component_Object_Model_HijackingT1122', 27: 'credential_accessTA0006Brute_ForceT1110', 28: 'discoveryTA0007Security_Software_DiscoveryT1063', 29: 'defense_evasionTA0005MasqueradingT1036', 30: 'lateral_movementTA0008Pass_the_HashT1075', 31: 'persistenceTA0003Winlogon_Helper_DLLT1004', 32: 'discoveryTA0007Password_Policy_DiscoveryT1201', 33: 'persistenceTA0003Windows_Management_Instrumentation_Event_SubscriptionT1084', 34: 'exfiltrationTA0010Data_EncryptedT1022', 35: 'persistenceTA0003Registry_Run_Keys_/_Startup_FolderT1060', 36: 'discoveryTA0007System_Network_Connections_DiscoveryT1049', 37: 'persistenceTA0003Logon_ScriptsT1037', 38: 'persistenceTA0003Component_Object_Model_HijackingT1122', 39: 'persistenceTA0003Image_File_Execution_Options_InjectionT1183', 40: 'lateral_movementTA0008Logon_ScriptsT1037', 41: 'lateral_movementTA0008Windows_Remote_ManagementT1028', 42: 'discoveryTA0007Permission_Groups_DiscoveryT1069', 43: 'persistenceTA0003AppInit_DLLsT1103', 44: 'exfiltrationTA0010Data_CompressedT1002', 45: 'credential_accessTA0006HookingT1179', 46: 'discoveryTA0007System_Owner/User_DiscoveryT1033', 47: 'persistenceTA0003HookingT1179', 48: 'persistenceTA0003Security_Support_ProviderT1101', 49: 'persistenceTA0003Netsh_Helper_DLLT1128', 50: 'persistenceTA0003Accessibility_FeaturesT1015'}\n",
            "\n",
            "decoder_word2idx: {'defense_evasionTA0005File_DeletionT1107': 1, 'collectionTA0009Data_StagedT1074': 2, 'exfiltrationTA0010Exfiltration_Over_Command_and_Control_ChannelT1041': 3, 'credential_accessTA0006Credential_DumpingT1003': 4, '<sos>': 5, '<eos>': 6, 'discoveryTA0007File_and_Directory_DiscoveryT1083': 7, 'lateral_movementTA0008Remote_File_CopyT1105': 8, 'discoveryTA0007Remote_System_DiscoveryT1018': 9, 'defense_evasionTA0005Deobfuscate/Decode_Files_or_InformationT1140': 10, 'collectionTA0009Email_CollectionT1114': 11, 'lateral_movementTA0008Remote_Desktop_ProtocolT1076': 12, 'defense_evasionTA0005Indicator_Removal_on_HostT1070': 13, 'persistenceTA0003New_ServiceT1050': 14, 'discoveryTA0007System_Time_DiscoveryT1124': 15, 'collectionTA0009Input_CaptureT1056': 16, 'credential_accessTA0006Credentials_in_FilesT1081': 17, 'credential_accessTA0006Input_CaptureT1056': 18, 'credential_accessTA0006Credentials_in_RegistryT1214': 19, 'credential_accessTA0006Brute_ForceT1110': 20, 'discoveryTA0007Network_Share_DiscoveryT1135': 21, 'lateral_movementTA0008Pass_the_HashT1075': 22, 'discoveryTA0007System_Service_DiscoveryT1007': 23, 'discoveryTA0007Query_RegistryT1012': 24, 'persistenceTA0003Scheduled_TaskT1053': 25, 'discoveryTA0007Account_DiscoveryT1087': 26, 'discoveryTA0007System_Network_Configuration_DiscoveryT1016': 27, 'discoveryTA0007System_Information_DiscoveryT1082': 28, 'defense_evasionTA0005Image_File_Execution_Options_InjectionT1183': 29, 'defense_evasionTA0005Component_Object_Model_HijackingT1122': 30, 'lateral_movementTA0008Windows_Remote_ManagementT1028': 31, 'discoveryTA0007Security_Software_DiscoveryT1063': 32, 'persistenceTA0003Registry_Run_Keys_/_Startup_FolderT1060': 33, 'exfiltrationTA0010Data_CompressedT1002': 34, 'discoveryTA0007System_Owner/User_DiscoveryT1033': 35, 'exfiltrationTA0010Data_EncryptedT1022': 36, 'lateral_movementTA0008Logon_ScriptsT1037': 37, 'discoveryTA0007Permission_Groups_DiscoveryT1069': 38, 'persistenceTA0003Component_Object_Model_HijackingT1122': 39, 'discoveryTA0007System_Network_Connections_DiscoveryT1049': 40, 'defense_evasionTA0005MasqueradingT1036': 41, 'persistenceTA0003Image_File_Execution_Options_InjectionT1183': 42, 'persistenceTA0003Windows_Management_Instrumentation_Event_SubscriptionT1084': 43, 'persistenceTA0003Winlogon_Helper_DLLT1004': 44, 'discoveryTA0007Password_Policy_DiscoveryT1201': 45, 'credential_accessTA0006HookingT1179': 46, 'persistenceTA0003Logon_ScriptsT1037': 47, 'persistenceTA0003Security_Support_ProviderT1101': 48, 'persistenceTA0003AppInit_DLLsT1103': 49, 'persistenceTA0003Netsh_Helper_DLLT1128': 50, 'persistenceTA0003HookingT1179': 51, 'persistenceTA0003Accessibility_FeaturesT1015': 52}\n",
            "decoder_idx2word: {1: 'defense_evasionTA0005File_DeletionT1107', 2: 'collectionTA0009Data_StagedT1074', 3: 'exfiltrationTA0010Exfiltration_Over_Command_and_Control_ChannelT1041', 4: 'credential_accessTA0006Credential_DumpingT1003', 5: '<sos>', 6: '<eos>', 7: 'discoveryTA0007File_and_Directory_DiscoveryT1083', 8: 'lateral_movementTA0008Remote_File_CopyT1105', 9: 'discoveryTA0007Remote_System_DiscoveryT1018', 10: 'defense_evasionTA0005Deobfuscate/Decode_Files_or_InformationT1140', 11: 'collectionTA0009Email_CollectionT1114', 12: 'lateral_movementTA0008Remote_Desktop_ProtocolT1076', 13: 'defense_evasionTA0005Indicator_Removal_on_HostT1070', 14: 'persistenceTA0003New_ServiceT1050', 15: 'discoveryTA0007System_Time_DiscoveryT1124', 16: 'collectionTA0009Input_CaptureT1056', 17: 'credential_accessTA0006Credentials_in_FilesT1081', 18: 'credential_accessTA0006Input_CaptureT1056', 19: 'credential_accessTA0006Credentials_in_RegistryT1214', 20: 'credential_accessTA0006Brute_ForceT1110', 21: 'discoveryTA0007Network_Share_DiscoveryT1135', 22: 'lateral_movementTA0008Pass_the_HashT1075', 23: 'discoveryTA0007System_Service_DiscoveryT1007', 24: 'discoveryTA0007Query_RegistryT1012', 25: 'persistenceTA0003Scheduled_TaskT1053', 26: 'discoveryTA0007Account_DiscoveryT1087', 27: 'discoveryTA0007System_Network_Configuration_DiscoveryT1016', 28: 'discoveryTA0007System_Information_DiscoveryT1082', 29: 'defense_evasionTA0005Image_File_Execution_Options_InjectionT1183', 30: 'defense_evasionTA0005Component_Object_Model_HijackingT1122', 31: 'lateral_movementTA0008Windows_Remote_ManagementT1028', 32: 'discoveryTA0007Security_Software_DiscoveryT1063', 33: 'persistenceTA0003Registry_Run_Keys_/_Startup_FolderT1060', 34: 'exfiltrationTA0010Data_CompressedT1002', 35: 'discoveryTA0007System_Owner/User_DiscoveryT1033', 36: 'exfiltrationTA0010Data_EncryptedT1022', 37: 'lateral_movementTA0008Logon_ScriptsT1037', 38: 'discoveryTA0007Permission_Groups_DiscoveryT1069', 39: 'persistenceTA0003Component_Object_Model_HijackingT1122', 40: 'discoveryTA0007System_Network_Connections_DiscoveryT1049', 41: 'defense_evasionTA0005MasqueradingT1036', 42: 'persistenceTA0003Image_File_Execution_Options_InjectionT1183', 43: 'persistenceTA0003Windows_Management_Instrumentation_Event_SubscriptionT1084', 44: 'persistenceTA0003Winlogon_Helper_DLLT1004', 45: 'discoveryTA0007Password_Policy_DiscoveryT1201', 46: 'credential_accessTA0006HookingT1179', 47: 'persistenceTA0003Logon_ScriptsT1037', 48: 'persistenceTA0003Security_Support_ProviderT1101', 49: 'persistenceTA0003AppInit_DLLsT1103', 50: 'persistenceTA0003Netsh_Helper_DLLT1128', 51: 'persistenceTA0003HookingT1179', 52: 'persistenceTA0003Accessibility_FeaturesT1015'}\n",
            "\n",
            "encoder_input_indices[0]: [9, 1, 24, 9, 4] \n",
            "decoder_input_indices[0]: [5, 25, 28, 11] \n",
            "decoder_target_indices[0]: [25, 28, 11, 6] \n",
            "\n",
            "encoder_input_indices[69]: [42, 4, 18, 24, 42] \n",
            "decoder_input_indices[69]: [5, 9, 2, 22] \n",
            "decoder_target_indices[69]: [9, 2, 22, 6] \n",
            "\n",
            "encoder_input_indices[169]: [3, 1, 3, 16, 24] \n",
            "decoder_input_indices[169]: [5, 1, 9, 38, 1, 22] \n",
            "decoder_target_indices[169]: [1, 9, 38, 1, 22, 6] \n",
            "\n",
            "encoder_input_indices[650]: [1, 9, 5, 16, 3] \n",
            "decoder_input_indices[650]: [5, 27, 11, 22, 11, 3, 1] \n",
            "decoder_target_indices[650]: [27, 11, 22, 11, 3, 1, 6] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eo_E8udOX28K"
      },
      "source": [
        "# Padding, Split & One-hot ðŸ”¥"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6TtbCuGV3aV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e24ac49-86ff-411b-8970-7fc2fd005622"
      },
      "source": [
        "max_encoder_seq_length = max([len(sequence) for sequence in encoder_input_indices])\n",
        "max_decoder_seq_length = max([len(sequence) for sequence in decoder_input_indices])\n",
        "\n",
        "print(\"Max sequence length for encoder:\", max_encoder_seq_length)\n",
        "print(\"Max sequence length for decoder:\", max_decoder_seq_length)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sequence length for encoder: 5\n",
            "Max sequence length for decoder: 31\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIV_Ea8fWPQJ"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "def get_padded_inputs(encoder_input_indices, decoder_input_indices, decoder_target_indices):\n",
        "    \n",
        "    padded_decoder_input = pad_sequences(decoder_input_indices, maxlen=max_decoder_seq_length, dtype='int32', padding='post')\n",
        "    padded_decoder_target = pad_sequences(decoder_target_indices, maxlen=max_decoder_seq_length, dtype='int32', padding='post')\n",
        "    print(\"\\npadded_decoder_input[0]\", padded_decoder_input[0])\n",
        "    print(\"padded_decoder_target[0]\", padded_decoder_target[0])\n",
        "    print(\"padded_decoder_input[69]\", padded_decoder_input[69])\n",
        "    print(\"padded_decoder_target[69\", padded_decoder_target[69])\n",
        "\n",
        "    return padded_decoder_input, padded_decoder_target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QT9idd7lWQwB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0400d567-74c3-472e-cf85-abfdf78e240a"
      },
      "source": [
        "padded_decoder_input, padded_decoder_target = get_padded_inputs(encoder_input_indices, decoder_input_indices, decoder_target_indices)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "padded_decoder_input[0] [ 5 25 28 11  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0]\n",
            "padded_decoder_target[0] [25 28 11  6  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0]\n",
            "padded_decoder_input[69] [ 5  9  2 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0]\n",
            "padded_decoder_target[69 [ 9  2 22  6  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsHno1djWj7E"
      },
      "source": [
        "def get_train_test_data(num_train_sample, encoder_input_indices, padded_decoder_input, padded_decoder_target):\n",
        "    num_total_sample = len(encoder_input_indices)\n",
        "    random.seed(69)\n",
        "    random_indices = list(range(num_total_sample))\n",
        "    random.shuffle(random_indices)\n",
        "    # print(random_indices)\n",
        "    encoder_train_input = [encoder_input_indices[i] for i in random_indices[:num_train_sample]]\n",
        "    decoder_train_input = [padded_decoder_input[i] for i in random_indices[:num_train_sample]]\n",
        "    decoder_train_target = [padded_decoder_target[i] for i in random_indices[:num_train_sample]]\n",
        "\n",
        "    encoder_test_input = [encoder_input_indices[i] for i in random_indices[num_train_sample:]]\n",
        "    decoder_test_input = [padded_decoder_input[i] for i in random_indices[num_train_sample:]]\n",
        "    decoder_test_target = [padded_decoder_target[i] for i in random_indices[num_train_sample:]]\n",
        "\n",
        "    print(\"Number of training samples:\", len(encoder_train_input))\n",
        "    print(\"Number of testing samples:\", len(encoder_test_input))\n",
        "\n",
        "    print(\"\\nencoder_train_input[0]:\", encoder_train_input[0], \"\\ndecoder_train_input[0]:\", decoder_train_input[0], \"\\ndecoder_train_target[0]:\", decoder_train_target[0], \"\\n\")\n",
        "    print(\"encoder_train_input[69]:\", encoder_train_input[69], \"\\ndecoder_train_input[69]:\", decoder_train_input[69], \"\\ndecoder_train_target[69]:\", decoder_train_target[69], \"\\n\")\n",
        "    print(\"encoder_test_input[0]:\", encoder_test_input[0], \"\\ndecoder_test_input[0]:\", decoder_test_input[0], \"\\ndecoder_test_target[0]:\", decoder_test_target[0], \"\\n\")\n",
        "    print(\"encoder_test_input[15]:\", encoder_test_input[15], \"\\ndecoder_test_input[15]:\", decoder_test_input[15], \"\\ndecoder_test_target[15]:\", decoder_test_target[15], \"\\n\")\n",
        "\n",
        "    return encoder_train_input, decoder_train_input, decoder_train_target, encoder_test_input, decoder_test_input, decoder_test_target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lf2k4LhIWmXU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c31a5552-2cfe-49fe-9896-59b4bfe42336"
      },
      "source": [
        "# split the data into train and test set\n",
        "num_total_sample = len(encoder_input_indices)\n",
        "num_train_sample = int(num_total_sample * 0.8)\n",
        "encoder_train_input, decoder_train_input, decoder_train_target, encoder_test_input, decoder_test_input, decoder_test_target \\\n",
        "= \\\n",
        "get_train_test_data(num_train_sample, encoder_input_indices, padded_decoder_input, padded_decoder_target)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training samples: 5468\n",
            "Number of testing samples: 1367\n",
            "\n",
            "encoder_train_input[0]: [26, 2, 3, 4, 34] \n",
            "decoder_train_input[0]: [ 5  2 30 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0] \n",
            "decoder_train_target[0]: [ 2 30 10  6  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0] \n",
            "\n",
            "encoder_train_input[69]: [6, 49, 5, 7, 1] \n",
            "decoder_train_input[69]: [ 5 21  7  2  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0] \n",
            "decoder_train_target[69]: [21  7  2  3  6  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0] \n",
            "\n",
            "encoder_test_input[0]: [30, 30, 3, 8, 18] \n",
            "decoder_test_input[0]: [ 5 26 28  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0] \n",
            "decoder_test_target[0]: [26 28  1  6  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0] \n",
            "\n",
            "encoder_test_input[15]: [1, 5, 4, 2, 3] \n",
            "decoder_test_input[15]: [ 5 36 15  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0] \n",
            "decoder_test_target[15]: [36 15  3  6  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ydGeywXXNLL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ac686e7-ac39-43be-f3b2-ce1b590bc979"
      },
      "source": [
        "num_encoder_tokens = max(encoder_word2idx.values())\n",
        "num_decoder_tokens = max(decoder_word2idx.values())\n",
        "\n",
        "print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
        "print(\"Number of unique output tokens:\", num_decoder_tokens)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of unique input tokens: 50\n",
            "Number of unique output tokens: 52\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1TwaXXEXUX6"
      },
      "source": [
        "def convert_to_onehot(encoder_train_input, decoder_train_input, decoder_train_target):    \n",
        "    encoder_train_input_oh = tf.one_hot(encoder_train_input, num_encoder_tokens+1, dtype='int32').numpy() # +1 for 0s (were added for padding)\n",
        "    decoder_train_input_oh = tf.one_hot(decoder_train_input, num_decoder_tokens+1, dtype='int32').numpy()\n",
        "    decoder_train_target_oh = tf.one_hot(decoder_train_target, num_decoder_tokens+1, dtype='int32').numpy()\n",
        "\n",
        "    return encoder_train_input_oh, decoder_train_input_oh, decoder_train_target_oh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huk0x2QsXVe8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3565e2d0-f192-4e26-bbbd-a34cbbaa1437"
      },
      "source": [
        "encoder_train_input_oh, decoder_train_input_oh, decoder_train_target_oh \\\n",
        "= \\\n",
        "convert_to_onehot(encoder_train_input, decoder_train_input, decoder_train_target)\n",
        "\n",
        "print(\"encoder_train_input_oh shape:\", encoder_train_input_oh.shape)\n",
        "print(\"decoder_train_input_oh shape:\", decoder_train_input_oh.shape)\n",
        "print(\"decoder_train_target_oh shape:\", decoder_train_target_oh.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "encoder_train_input_oh shape: (5468, 5, 51)\n",
            "decoder_train_input_oh shape: (5468, 31, 53)\n",
            "decoder_train_target_oh shape: (5468, 31, 53)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSsvmlHsXbwg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4677571c-df75-4c36-c8e1-3b2eed9c4d9a"
      },
      "source": [
        "encoder_train_input_oh[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWIkBfKNX8VU"
      },
      "source": [
        "# Defining the training model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPVm2H4tX9oq"
      },
      "source": [
        "from tensorflow.keras import Model, layers, Input\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "from matplotlib import pyplot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHFimqdfhPSM"
      },
      "source": [
        "def plot_history(history):\n",
        "\n",
        "    max_val_acc = max(history.history['val_accuracy'])\n",
        "    max_val_acc_idx = np.argmax(history.history['val_accuracy'])\n",
        "    print(\"Max Validation Accuracy\", max_val_acc, \" at epoch:\", max_val_acc_idx+1, \" with Training Accuracy\", history.history['accuracy'][max_val_acc_idx])\n",
        "    print()\n",
        "\n",
        "    # plot metrics\n",
        "    pyplot.plot(history.history['loss'])\n",
        "    pyplot.plot(history.history['val_loss'])\n",
        "    pyplot.show()\n",
        "    pyplot.plot(history.history['accuracy'])\n",
        "    pyplot.plot(history.history['val_accuracy'])\n",
        "    pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnSQKthKT5Yw"
      },
      "source": [
        "def get_stacked_model(n_units):\n",
        "\n",
        "    K.clear_session()\n",
        "    # credit: https://stackoverflow.com/a/56693548/7737870\n",
        "    # latent_dims is an array which defines the depth of the encoder/decoder, as well as how large\n",
        "    # the layers should be. So an array of sizes [a,b,c]  would produce a depth-3 encoder and decoder\n",
        "    # with layer sizes equal to [c,b,a] and [a,b,c] respectively.\n",
        "    encoder_inputs = Input(shape=(None, num_encoder_tokens+1), name=\"encoder_input\")\n",
        "    encoder_outputs = encoder_inputs\n",
        "    encoder_states = []\n",
        "    for j in range(len(n_units))[::-1]:\n",
        "        encoder_outputs, h, c = layers.LSTM(n_units[j], return_state=True, return_sequences=bool(j), dropout=0.2, name=f\"encoder_lstm_{len(n_units) - j}\")(encoder_outputs)\n",
        "        encoder_states += [h, c]\n",
        "\n",
        "    decoder_inputs = Input(shape=(None, num_decoder_tokens+1), name=\"decoder_input\")\n",
        "    masked_decoder_inputs = layers.Masking(mask_value=0, name=\"decoder_masking\")(decoder_inputs)\n",
        "    decoder_outputs = masked_decoder_inputs\n",
        "    output_layers = []\n",
        "    for j in range(len(n_units)):\n",
        "        output_layers.append( \\\n",
        "            layers.LSTM(n_units[len(n_units) - j - 1], return_sequences=True, return_state=True, name=f\"decoder_lstm_{j+1}\") \\\n",
        "        )\n",
        "        decoder_outputs, dh, dc = output_layers[-1](decoder_outputs, initial_state=encoder_states[2*j:2*(j+1)])\n",
        "\n",
        "    decoder_dense = layers.Dense(num_decoder_tokens+1, activation='softmax', name=\"decoder_dense\")\n",
        "    decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "    # define training model\n",
        "    stacked_model = Model([encoder_inputs, decoder_inputs], decoder_outputs, name=\"stacked_model\")\n",
        "\n",
        "    return stacked_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvT_c5bh8suK"
      },
      "source": [
        "def get_stacked_model_with_dropout(n_units, dropout_at, dropout_value):\n",
        "\n",
        "    K.clear_session()\n",
        "    # credit: https://stackoverflow.com/a/56693548/7737870\n",
        "    # latent_dims is an array which defines the depth of the encoder/decoder, as well as how large\n",
        "    # the layers should be. So an array of sizes [a,b,c]  would produce a depth-3 encoder and decoder\n",
        "    # with layer sizes equal to [c,b,a] and [a,b,c] respectively.\n",
        "    encoder_inputs = Input(shape=(None, num_encoder_tokens+1), name=\"encoder_input\")\n",
        "    encoder_outputs = encoder_inputs\n",
        "    encoder_states = []\n",
        "    for j in range(len(n_units))[::-1]:\n",
        "        encoder_outputs, h, c = layers.LSTM(n_units[j], return_state=True, return_sequences=bool(j), name=f\"encoder_lstm_{len(n_units) - j}\")(encoder_outputs)\n",
        "        encoder_states += [h, c]\n",
        "\n",
        "    decoder_inputs = Input(shape=(None, num_decoder_tokens+1), name=\"decoder_input\")\n",
        "    masked_decoder_inputs = layers.Masking(mask_value=0, name=\"decoder_masking\")(decoder_inputs)\n",
        "    decoder_outputs = masked_decoder_inputs\n",
        "    output_layers = []\n",
        "\n",
        "\n",
        "    dropout_idx = 0\n",
        "    j = 0\n",
        "    for i in range(len(n_units) + len(dropout_at)):\n",
        "        if i == dropout_at[dropout_idx]:\n",
        "            output_layers.append(layers.Dropout(dropout_value[dropout_idx]))\n",
        "            decoder_outputs = output_layers[-1](decoder_outputs)\n",
        "            if dropout_idx < len(dropout_at)-1:\n",
        "                dropout_idx += 1\n",
        "        else:\n",
        "            output_layers.append( \\\n",
        "                layers.LSTM(n_units[len(n_units) - j - 1], return_sequences=True, return_state=True, name=f\"decoder_lstm_{j+1}\") \\\n",
        "            )\n",
        "            decoder_outputs, dh, dc = output_layers[-1](decoder_outputs, initial_state=encoder_states[2*j:2*(j+1)])\n",
        "            j += 1\n",
        "\n",
        "    decoder_dense = layers.Dense(num_decoder_tokens+1, activation='softmax', name=\"decoder_dense\")\n",
        "    decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "    # define training model\n",
        "    stacked_model = Model([encoder_inputs, decoder_inputs], decoder_outputs, name=\"stacked_model\")\n",
        "\n",
        "    return stacked_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQuHwMW5Mo4t"
      },
      "source": [
        "# this model will pass context vector from only the last encoder layer to the first decoder layer\n",
        "def get_stacked_model_last_state_only(n_units):\n",
        "\n",
        "    K.clear_session()\n",
        "    # credit: https://stackoverflow.com/a/56693548/7737870\n",
        "    # latent_dims is an array which defines the depth of the encoder/decoder, as well as how large\n",
        "    # the layers should be. So an array of sizes [a,b,c]  would produce a depth-3 encoder and decoder\n",
        "    # with layer sizes equal to [c,b,a] and [a,b,c] respectively.\n",
        "\n",
        "    # define encoder\n",
        "    encoder_inputs = Input(shape=(None, num_encoder_tokens+1), name=\"encoder_input\")\n",
        "    encoder_outputs = encoder_inputs\n",
        "    for j in range(len(n_units))[::-1]:\n",
        "        encoder_outputs, h, c = layers.LSTM(n_units[j], return_state=True, return_sequences=bool(j), name=f\"encoder_lstm_{len(n_units) - j}\")(encoder_outputs)\n",
        "    encoder_states = [h, c]\n",
        "\n",
        "    # define decoder\n",
        "    decoder_inputs = Input(shape=(None, num_decoder_tokens+1), name=\"decoder_input\")\n",
        "    masked_decoder_inputs = layers.Masking(mask_value=0, name=\"decoder_masking\")(decoder_inputs)\n",
        "    decoder_outputs = masked_decoder_inputs\n",
        "    output_layers = []\n",
        "\n",
        "    # add context vector as the first decoder initial state\n",
        "    output_layers.append( \\\n",
        "            layers.LSTM(n_units[len(n_units) - 1], return_sequences=True, return_state=True, name=f\"decoder_lstm_1\") \\\n",
        "        )\n",
        "    decoder_outputs, dh, dc = output_layers[-1](decoder_outputs, initial_state=encoder_states)\n",
        "    # add other decoder layers\n",
        "    for j in range(1, len(n_units)):\n",
        "        output_layers.append( \\\n",
        "            layers.LSTM(n_units[len(n_units) - j - 1], return_sequences=True, return_state=True, name=f\"decoder_lstm_{j+1}\") \\\n",
        "        )\n",
        "        decoder_outputs, dh, dc = output_layers[-1](decoder_outputs)\n",
        "\n",
        "    decoder_dense = layers.Dense(num_decoder_tokens+1, activation='softmax', name=\"decoder_dense\")\n",
        "    decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "    # define training model\n",
        "    stacked_model = Model([encoder_inputs, decoder_inputs], decoder_outputs, name=\"stacked_model\")\n",
        "\n",
        "    return stacked_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeAZQC8a3Ryp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e44c5c0-bd13-4e18-b348-4c1cfb564287"
      },
      "source": [
        "n_units = [1024, 800, 128]\n",
        "# dropout_at = [1]\n",
        "# dropout_value = [0.2]\n",
        "stacked_model = get_stacked_model(n_units)\n",
        "# stacked_model = get_stacked_model_with_dropout(n_units, dropout_at, dropout_value)\n",
        "stacked_model.summary()\n",
        "\n",
        "# compile\n",
        "stacked_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"stacked_model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "decoder_input (InputLayer)      [(None, None, 53)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "encoder_input (InputLayer)      [(None, None, 51)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "decoder_masking (Masking)       (None, None, 53)     0           decoder_input[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "encoder_lstm_1 (LSTM)           [(None, None, 128),  92160       encoder_input[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder_lstm_1 (LSTM)           [(None, None, 128),  93184       decoder_masking[0][0]            \n",
            "                                                                 encoder_lstm_1[0][1]             \n",
            "                                                                 encoder_lstm_1[0][2]             \n",
            "__________________________________________________________________________________________________\n",
            "encoder_lstm_2 (LSTM)           [(None, None, 800),  2972800     encoder_lstm_1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder_lstm_2 (LSTM)           [(None, None, 800),  2972800     decoder_lstm_1[0][0]             \n",
            "                                                                 encoder_lstm_2[0][1]             \n",
            "                                                                 encoder_lstm_2[0][2]             \n",
            "__________________________________________________________________________________________________\n",
            "encoder_lstm_3 (LSTM)           [(None, 1024), (None 7475200     encoder_lstm_2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder_lstm_3 (LSTM)           [(None, None, 1024), 7475200     decoder_lstm_2[0][0]             \n",
            "                                                                 encoder_lstm_3[0][1]             \n",
            "                                                                 encoder_lstm_3[0][2]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder_dense (Dense)           (None, None, 53)     54325       decoder_lstm_3[0][0]             \n",
            "==================================================================================================\n",
            "Total params: 21,135,669\n",
            "Trainable params: 21,135,669\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrzaWa19YOSp"
      },
      "source": [
        "# from tensorflow.keras.utils import plot_model\n",
        "# plot_model(stacked_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLN5_Gc_yDyb"
      },
      "source": [
        "# # Subclass ModelCheckpoint\n",
        "# class MyModelCheckpoint(ModelCheckpoint):\n",
        "\n",
        "#     def __init__(self, *args, **kwargs):\n",
        "#         super(MyModelCheckpoint, self).__init__(*args, **kwargs)\n",
        "\n",
        "\n",
        "#     # redefine the save so it only activates after 200 epochs\n",
        "#     def on_epoch_end(self, epoch, logs=None):\n",
        "#         if epoch > 150: super(MyModelCheckpoint, self).on_epoch_end(epoch, logs)\n",
        "\n",
        "# chkpoint_filepath = \"(5_enc,3_layer,1024_800_128_units)augmented_s2s_stacked\"\n",
        "# model_checkpoint_callback = MyModelCheckpoint(\n",
        "#     filepath=chkpoint_filepath,\n",
        "#     save_best_only=True,\n",
        "#     monitor='val_accuracy',\n",
        "#     mode='max',\n",
        "#     verbose=0\n",
        "# )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uaThsTr29fMF"
      },
      "source": [
        "# K.clear_session()\n",
        "# # fit\n",
        "# history = stacked_model.fit( \\\n",
        "#             [encoder_train_input_oh, decoder_train_input_oh], decoder_train_target_oh, \\\n",
        "#             batch_size=64, \\\n",
        "#             epochs=500, \\\n",
        "#             validation_split=0.1,\n",
        "#             callbacks=model_checkpoint_callback\n",
        "#         )\n",
        "# # stacked_model.save(\"(5_enc,1_layer,32_units)augmented_s2s_stacked\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mxH3sCVvPTH"
      },
      "source": [
        "# Subclass ModelCheckpoint\n",
        "class MyModelCheckpoint(ModelCheckpoint):\n",
        "\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super(MyModelCheckpoint, self).__init__(*args, **kwargs)\n",
        "\n",
        "\n",
        "    # redefine the save so it only activates after a number of epochs\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if epoch > 150: super(MyModelCheckpoint, self).on_epoch_end(epoch, logs)\n",
        "\n",
        "chkpoint_filepath = \"(5_enc,3_layer,1024_800_128_units)augmented_s2s_stacked\"\n",
        "model_checkpoint_callback = MyModelCheckpoint(\n",
        "    filepath=chkpoint_filepath,\n",
        "    save_best_only=True,\n",
        "    monitor='accuracy',\n",
        "    mode='max',\n",
        "    verbose=0\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GwypQR1ugiv",
        "outputId": "395e89ad-8dc1-4430-9ebf-97c08d9cb659"
      },
      "source": [
        "K.clear_session()\n",
        "# fit\n",
        "history = stacked_model.fit( \\\n",
        "            [encoder_train_input_oh, decoder_train_input_oh], decoder_train_target_oh, \\\n",
        "            batch_size=64, \\\n",
        "            epochs=500, \\\n",
        "            callbacks=model_checkpoint_callback\n",
        "        )\n",
        "# stacked_model.save(\"(5_enc,1_layer,32_units)augmented_s2s_stacked\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "86/86 [==============================] - 48s 62ms/step - loss: 1.4442 - accuracy: 0.6934\n",
            "Epoch 2/500\n",
            "86/86 [==============================] - 5s 60ms/step - loss: 0.8246 - accuracy: 0.7723\n",
            "Epoch 3/500\n",
            "86/86 [==============================] - 5s 61ms/step - loss: 0.7449 - accuracy: 0.7933\n",
            "Epoch 4/500\n",
            "86/86 [==============================] - 5s 61ms/step - loss: 0.7063 - accuracy: 0.7981\n",
            "Epoch 5/500\n",
            "86/86 [==============================] - 5s 61ms/step - loss: 0.6680 - accuracy: 0.8035\n",
            "Epoch 6/500\n",
            "86/86 [==============================] - 5s 61ms/step - loss: 0.6134 - accuracy: 0.8167\n",
            "Epoch 7/500\n",
            "86/86 [==============================] - 5s 61ms/step - loss: 0.5726 - accuracy: 0.8273\n",
            "Epoch 8/500\n",
            "86/86 [==============================] - 5s 61ms/step - loss: 0.5169 - accuracy: 0.8452\n",
            "Epoch 9/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.4605 - accuracy: 0.8634\n",
            "Epoch 10/500\n",
            "86/86 [==============================] - 5s 61ms/step - loss: 0.4021 - accuracy: 0.8810\n",
            "Epoch 11/500\n",
            "86/86 [==============================] - 5s 61ms/step - loss: 0.3484 - accuracy: 0.8976\n",
            "Epoch 12/500\n",
            "86/86 [==============================] - 5s 61ms/step - loss: 0.3100 - accuracy: 0.9092\n",
            "Epoch 13/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.2750 - accuracy: 0.9195\n",
            "Epoch 14/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.2499 - accuracy: 0.9266\n",
            "Epoch 15/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.2249 - accuracy: 0.9338\n",
            "Epoch 16/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.2095 - accuracy: 0.9385\n",
            "Epoch 17/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.1901 - accuracy: 0.9442\n",
            "Epoch 18/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.1732 - accuracy: 0.9487\n",
            "Epoch 19/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.1685 - accuracy: 0.9498\n",
            "Epoch 20/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.1505 - accuracy: 0.9561\n",
            "Epoch 21/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.1410 - accuracy: 0.9586\n",
            "Epoch 22/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.1282 - accuracy: 0.9625\n",
            "Epoch 23/500\n",
            "86/86 [==============================] - 5s 61ms/step - loss: 0.1236 - accuracy: 0.9631\n",
            "Epoch 24/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.1197 - accuracy: 0.9648\n",
            "Epoch 25/500\n",
            "86/86 [==============================] - 5s 61ms/step - loss: 0.1090 - accuracy: 0.9683\n",
            "Epoch 26/500\n",
            "86/86 [==============================] - 5s 61ms/step - loss: 0.1030 - accuracy: 0.9696\n",
            "Epoch 27/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.1000 - accuracy: 0.9705\n",
            "Epoch 28/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0891 - accuracy: 0.9743\n",
            "Epoch 29/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0879 - accuracy: 0.9746\n",
            "Epoch 30/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0857 - accuracy: 0.9751\n",
            "Epoch 31/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0796 - accuracy: 0.9773\n",
            "Epoch 32/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0769 - accuracy: 0.9779\n",
            "Epoch 33/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0771 - accuracy: 0.9774\n",
            "Epoch 34/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0733 - accuracy: 0.9788\n",
            "Epoch 35/500\n",
            "86/86 [==============================] - 5s 61ms/step - loss: 0.0728 - accuracy: 0.9789\n",
            "Epoch 36/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0655 - accuracy: 0.9812\n",
            "Epoch 37/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0650 - accuracy: 0.9810\n",
            "Epoch 38/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0643 - accuracy: 0.9810\n",
            "Epoch 39/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0615 - accuracy: 0.9822\n",
            "Epoch 40/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0604 - accuracy: 0.9828\n",
            "Epoch 41/500\n",
            "86/86 [==============================] - 5s 61ms/step - loss: 0.0602 - accuracy: 0.9823\n",
            "Epoch 42/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0602 - accuracy: 0.9822\n",
            "Epoch 43/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0590 - accuracy: 0.9827\n",
            "Epoch 44/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0553 - accuracy: 0.9838\n",
            "Epoch 45/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0543 - accuracy: 0.9842\n",
            "Epoch 46/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0519 - accuracy: 0.9850\n",
            "Epoch 47/500\n",
            "86/86 [==============================] - 5s 61ms/step - loss: 0.0537 - accuracy: 0.9845\n",
            "Epoch 48/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0516 - accuracy: 0.9844\n",
            "Epoch 49/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0479 - accuracy: 0.9857\n",
            "Epoch 50/500\n",
            "86/86 [==============================] - 5s 61ms/step - loss: 0.0497 - accuracy: 0.9854\n",
            "Epoch 51/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0489 - accuracy: 0.9854\n",
            "Epoch 52/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0480 - accuracy: 0.9859\n",
            "Epoch 53/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0481 - accuracy: 0.9858\n",
            "Epoch 54/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0472 - accuracy: 0.9863\n",
            "Epoch 55/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0455 - accuracy: 0.9870\n",
            "Epoch 56/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0441 - accuracy: 0.9869\n",
            "Epoch 57/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0442 - accuracy: 0.9873\n",
            "Epoch 58/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0434 - accuracy: 0.9871\n",
            "Epoch 59/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0450 - accuracy: 0.9867\n",
            "Epoch 60/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0448 - accuracy: 0.9872\n",
            "Epoch 61/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0412 - accuracy: 0.9880\n",
            "Epoch 62/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0409 - accuracy: 0.9880\n",
            "Epoch 63/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0429 - accuracy: 0.9872\n",
            "Epoch 64/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0434 - accuracy: 0.9874\n",
            "Epoch 65/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0417 - accuracy: 0.9880\n",
            "Epoch 66/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0406 - accuracy: 0.9882\n",
            "Epoch 67/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0397 - accuracy: 0.9883\n",
            "Epoch 68/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0388 - accuracy: 0.9885\n",
            "Epoch 69/500\n",
            "86/86 [==============================] - 5s 61ms/step - loss: 0.0388 - accuracy: 0.9887\n",
            "Epoch 70/500\n",
            "86/86 [==============================] - 5s 61ms/step - loss: 0.0400 - accuracy: 0.9879\n",
            "Epoch 71/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0384 - accuracy: 0.9889\n",
            "Epoch 72/500\n",
            "86/86 [==============================] - 5s 61ms/step - loss: 0.0383 - accuracy: 0.9888\n",
            "Epoch 73/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0382 - accuracy: 0.9888\n",
            "Epoch 74/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0376 - accuracy: 0.9890\n",
            "Epoch 75/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0372 - accuracy: 0.9892\n",
            "Epoch 76/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0370 - accuracy: 0.9891\n",
            "Epoch 77/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0383 - accuracy: 0.9887\n",
            "Epoch 78/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0363 - accuracy: 0.9895\n",
            "Epoch 79/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0378 - accuracy: 0.9889\n",
            "Epoch 80/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0324 - accuracy: 0.9905\n",
            "Epoch 81/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0351 - accuracy: 0.9898\n",
            "Epoch 82/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0365 - accuracy: 0.9896\n",
            "Epoch 83/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0379 - accuracy: 0.9889\n",
            "Epoch 84/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0323 - accuracy: 0.9905\n",
            "Epoch 85/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0341 - accuracy: 0.9900\n",
            "Epoch 86/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0349 - accuracy: 0.9902\n",
            "Epoch 87/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0378 - accuracy: 0.9892\n",
            "Epoch 88/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0343 - accuracy: 0.9900\n",
            "Epoch 89/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0346 - accuracy: 0.9899\n",
            "Epoch 90/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0350 - accuracy: 0.9899\n",
            "Epoch 91/500\n",
            "86/86 [==============================] - 5s 64ms/step - loss: 0.0323 - accuracy: 0.9903\n",
            "Epoch 92/500\n",
            "86/86 [==============================] - 5s 64ms/step - loss: 0.0356 - accuracy: 0.9894\n",
            "Epoch 93/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0345 - accuracy: 0.9897\n",
            "Epoch 94/500\n",
            "86/86 [==============================] - 5s 64ms/step - loss: 0.0329 - accuracy: 0.9902\n",
            "Epoch 95/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0328 - accuracy: 0.9903\n",
            "Epoch 96/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0326 - accuracy: 0.9905\n",
            "Epoch 97/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0326 - accuracy: 0.9903\n",
            "Epoch 98/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0300 - accuracy: 0.9912\n",
            "Epoch 99/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0292 - accuracy: 0.9918\n",
            "Epoch 100/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0328 - accuracy: 0.9904\n",
            "Epoch 101/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0335 - accuracy: 0.9903\n",
            "Epoch 102/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0311 - accuracy: 0.9908\n",
            "Epoch 103/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0339 - accuracy: 0.9899\n",
            "Epoch 104/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0322 - accuracy: 0.9905\n",
            "Epoch 105/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0292 - accuracy: 0.9913\n",
            "Epoch 106/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0319 - accuracy: 0.9907\n",
            "Epoch 107/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0301 - accuracy: 0.9912\n",
            "Epoch 108/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0303 - accuracy: 0.9910\n",
            "Epoch 109/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0297 - accuracy: 0.9912\n",
            "Epoch 110/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0305 - accuracy: 0.9910\n",
            "Epoch 111/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0320 - accuracy: 0.9909\n",
            "Epoch 112/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0307 - accuracy: 0.9912\n",
            "Epoch 113/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0319 - accuracy: 0.9907\n",
            "Epoch 114/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0298 - accuracy: 0.9912\n",
            "Epoch 115/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0309 - accuracy: 0.9909\n",
            "Epoch 116/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0305 - accuracy: 0.9911\n",
            "Epoch 117/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0293 - accuracy: 0.9914\n",
            "Epoch 118/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0291 - accuracy: 0.9916\n",
            "Epoch 119/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0314 - accuracy: 0.9908\n",
            "Epoch 120/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0285 - accuracy: 0.9916\n",
            "Epoch 121/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0285 - accuracy: 0.9915\n",
            "Epoch 122/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0276 - accuracy: 0.9921\n",
            "Epoch 123/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0296 - accuracy: 0.9915\n",
            "Epoch 124/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0290 - accuracy: 0.9917\n",
            "Epoch 125/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0300 - accuracy: 0.9915\n",
            "Epoch 126/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0285 - accuracy: 0.9916\n",
            "Epoch 127/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0290 - accuracy: 0.9915\n",
            "Epoch 128/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0292 - accuracy: 0.9915\n",
            "Epoch 129/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0293 - accuracy: 0.9913\n",
            "Epoch 130/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0271 - accuracy: 0.9921\n",
            "Epoch 131/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0263 - accuracy: 0.9921\n",
            "Epoch 132/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0290 - accuracy: 0.9915\n",
            "Epoch 133/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0296 - accuracy: 0.9911\n",
            "Epoch 134/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0278 - accuracy: 0.9919\n",
            "Epoch 135/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0269 - accuracy: 0.9922\n",
            "Epoch 136/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0297 - accuracy: 0.9912\n",
            "Epoch 137/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0276 - accuracy: 0.9919\n",
            "Epoch 138/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0272 - accuracy: 0.9917\n",
            "Epoch 139/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0277 - accuracy: 0.9919\n",
            "Epoch 140/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0270 - accuracy: 0.9919\n",
            "Epoch 141/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0277 - accuracy: 0.9919\n",
            "Epoch 142/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0270 - accuracy: 0.9922\n",
            "Epoch 143/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0263 - accuracy: 0.9923\n",
            "Epoch 144/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0299 - accuracy: 0.9912\n",
            "Epoch 145/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0269 - accuracy: 0.9920\n",
            "Epoch 146/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0285 - accuracy: 0.9913\n",
            "Epoch 147/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0270 - accuracy: 0.9918\n",
            "Epoch 148/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0268 - accuracy: 0.9921\n",
            "Epoch 149/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0277 - accuracy: 0.9919\n",
            "Epoch 150/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0290 - accuracy: 0.9915\n",
            "Epoch 151/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0281 - accuracy: 0.9921\n",
            "Epoch 152/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0277 - accuracy: 0.9917\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: (5_enc,3_layer,1024_800_128_units)augmented_s2s_stacked/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: (5_enc,3_layer,1024_800_128_units)augmented_s2s_stacked/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 153/500\n",
            "86/86 [==============================] - 5s 61ms/step - loss: 0.0243 - accuracy: 0.9928\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: (5_enc,3_layer,1024_800_128_units)augmented_s2s_stacked/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: (5_enc,3_layer,1024_800_128_units)augmented_s2s_stacked/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 154/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0249 - accuracy: 0.9924\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: (5_enc,3_layer,1024_800_128_units)augmented_s2s_stacked/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: (5_enc,3_layer,1024_800_128_units)augmented_s2s_stacked/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 155/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0263 - accuracy: 0.9924\n",
            "Epoch 156/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0246 - accuracy: 0.9928\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: (5_enc,3_layer,1024_800_128_units)augmented_s2s_stacked/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: (5_enc,3_layer,1024_800_128_units)augmented_s2s_stacked/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 157/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0245 - accuracy: 0.9929\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: (5_enc,3_layer,1024_800_128_units)augmented_s2s_stacked/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: (5_enc,3_layer,1024_800_128_units)augmented_s2s_stacked/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 158/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0253 - accuracy: 0.9926\n",
            "Epoch 159/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0274 - accuracy: 0.9921\n",
            "Epoch 160/500\n",
            "86/86 [==============================] - 6s 64ms/step - loss: 0.0259 - accuracy: 0.9925\n",
            "Epoch 161/500\n",
            "86/86 [==============================] - 5s 64ms/step - loss: 0.0253 - accuracy: 0.9927\n",
            "Epoch 162/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0266 - accuracy: 0.9922\n",
            "Epoch 163/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0276 - accuracy: 0.9917\n",
            "Epoch 164/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0258 - accuracy: 0.9924\n",
            "Epoch 165/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0276 - accuracy: 0.9917\n",
            "Epoch 166/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0238 - accuracy: 0.9929\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: (5_enc,3_layer,1024_800_128_units)augmented_s2s_stacked/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: (5_enc,3_layer,1024_800_128_units)augmented_s2s_stacked/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 167/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0269 - accuracy: 0.9920\n",
            "Epoch 168/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0265 - accuracy: 0.9923\n",
            "Epoch 169/500\n",
            "86/86 [==============================] - 5s 64ms/step - loss: 0.0251 - accuracy: 0.9924\n",
            "Epoch 170/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0259 - accuracy: 0.9924\n",
            "Epoch 171/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0244 - accuracy: 0.9928\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: (5_enc,3_layer,1024_800_128_units)augmented_s2s_stacked/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: (5_enc,3_layer,1024_800_128_units)augmented_s2s_stacked/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 172/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0268 - accuracy: 0.9920\n",
            "Epoch 173/500\n",
            "86/86 [==============================] - 6s 65ms/step - loss: 0.0234 - accuracy: 0.9930\n",
            "Epoch 174/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0245 - accuracy: 0.9926\n",
            "Epoch 175/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0261 - accuracy: 0.9926\n",
            "Epoch 176/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0258 - accuracy: 0.9924\n",
            "Epoch 177/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0243 - accuracy: 0.9928\n",
            "Epoch 178/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0271 - accuracy: 0.9920\n",
            "Epoch 179/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0240 - accuracy: 0.9927\n",
            "Epoch 180/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0259 - accuracy: 0.9925\n",
            "Epoch 181/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0257 - accuracy: 0.9925\n",
            "Epoch 182/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0251 - accuracy: 0.9925\n",
            "Epoch 183/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0251 - accuracy: 0.9925\n",
            "Epoch 184/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0269 - accuracy: 0.9919\n",
            "Epoch 185/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0244 - accuracy: 0.9929\n",
            "Epoch 186/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0247 - accuracy: 0.9926\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: (5_enc,3_layer,1024_800_128_units)augmented_s2s_stacked/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: (5_enc,3_layer,1024_800_128_units)augmented_s2s_stacked/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 187/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0240 - accuracy: 0.9928\n",
            "Epoch 188/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0263 - accuracy: 0.9921\n",
            "Epoch 189/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0241 - accuracy: 0.9928\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: (5_enc,3_layer,1024_800_128_units)augmented_s2s_stacked/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: (5_enc,3_layer,1024_800_128_units)augmented_s2s_stacked/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 190/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0232 - accuracy: 0.9931\n",
            "Epoch 191/500\n",
            "86/86 [==============================] - 5s 64ms/step - loss: 0.0243 - accuracy: 0.9928\n",
            "Epoch 192/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0247 - accuracy: 0.9925\n",
            "Epoch 193/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0230 - accuracy: 0.9932\n",
            "Epoch 194/500\n",
            "86/86 [==============================] - 5s 64ms/step - loss: 0.0255 - accuracy: 0.9925\n",
            "Epoch 195/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0256 - accuracy: 0.9925\n",
            "Epoch 196/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0229 - accuracy: 0.9933\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: (5_enc,3_layer,1024_800_128_units)augmented_s2s_stacked/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: (5_enc,3_layer,1024_800_128_units)augmented_s2s_stacked/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 197/500\n",
            "86/86 [==============================] - 5s 61ms/step - loss: 0.0235 - accuracy: 0.9930\n",
            "Epoch 198/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0233 - accuracy: 0.9933\n",
            "Epoch 199/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0247 - accuracy: 0.9927\n",
            "Epoch 200/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0251 - accuracy: 0.9924\n",
            "Epoch 201/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0222 - accuracy: 0.9935\n",
            "Epoch 202/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0231 - accuracy: 0.9931\n",
            "Epoch 203/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0248 - accuracy: 0.9926\n",
            "Epoch 204/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0258 - accuracy: 0.9922\n",
            "Epoch 205/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0227 - accuracy: 0.9930\n",
            "Epoch 206/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0225 - accuracy: 0.9932\n",
            "Epoch 207/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0233 - accuracy: 0.9929\n",
            "Epoch 208/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0237 - accuracy: 0.9931\n",
            "Epoch 209/500\n",
            "86/86 [==============================] - 5s 61ms/step - loss: 0.0223 - accuracy: 0.9934\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: (5_enc,3_layer,1024_800_128_units)augmented_s2s_stacked/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: (5_enc,3_layer,1024_800_128_units)augmented_s2s_stacked/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 210/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0235 - accuracy: 0.9928\n",
            "Epoch 211/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0244 - accuracy: 0.9927\n",
            "Epoch 212/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0238 - accuracy: 0.9931\n",
            "Epoch 213/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0238 - accuracy: 0.9929\n",
            "Epoch 214/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0220 - accuracy: 0.9935\n",
            "Epoch 215/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0242 - accuracy: 0.9928\n",
            "Epoch 216/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0234 - accuracy: 0.9932\n",
            "Epoch 217/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0228 - accuracy: 0.9933\n",
            "Epoch 218/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0264 - accuracy: 0.9921\n",
            "Epoch 219/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0226 - accuracy: 0.9933\n",
            "Epoch 220/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0252 - accuracy: 0.9925\n",
            "Epoch 221/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0245 - accuracy: 0.9927\n",
            "Epoch 222/500\n",
            "86/86 [==============================] - 5s 61ms/step - loss: 0.0219 - accuracy: 0.9934\n",
            "Epoch 223/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0215 - accuracy: 0.9932\n",
            "Epoch 224/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0233 - accuracy: 0.9930\n",
            "Epoch 225/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0226 - accuracy: 0.9935\n",
            "Epoch 226/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0236 - accuracy: 0.9929\n",
            "Epoch 227/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0229 - accuracy: 0.9932\n",
            "Epoch 228/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0242 - accuracy: 0.9930\n",
            "Epoch 229/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0214 - accuracy: 0.9933\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: (5_enc,3_layer,1024_800_128_units)augmented_s2s_stacked/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: (5_enc,3_layer,1024_800_128_units)augmented_s2s_stacked/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 230/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0225 - accuracy: 0.9931\n",
            "Epoch 231/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0253 - accuracy: 0.9926\n",
            "Epoch 232/500\n",
            "86/86 [==============================] - 6s 64ms/step - loss: 0.0240 - accuracy: 0.9927\n",
            "Epoch 233/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0241 - accuracy: 0.9928\n",
            "Epoch 234/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0227 - accuracy: 0.9931\n",
            "Epoch 235/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0229 - accuracy: 0.9932\n",
            "Epoch 236/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0214 - accuracy: 0.9936\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: (5_enc,3_layer,1024_800_128_units)augmented_s2s_stacked/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: (5_enc,3_layer,1024_800_128_units)augmented_s2s_stacked/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 237/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0199 - accuracy: 0.9939\n",
            "Epoch 238/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0217 - accuracy: 0.9936\n",
            "Epoch 239/500\n",
            "86/86 [==============================] - 5s 61ms/step - loss: 0.0233 - accuracy: 0.9931\n",
            "Epoch 240/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0207 - accuracy: 0.9939\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: (5_enc,3_layer,1024_800_128_units)augmented_s2s_stacked/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: (5_enc,3_layer,1024_800_128_units)augmented_s2s_stacked/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 241/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0237 - accuracy: 0.9931\n",
            "Epoch 242/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0208 - accuracy: 0.9937\n",
            "Epoch 243/500\n",
            "86/86 [==============================] - 6s 65ms/step - loss: 0.0234 - accuracy: 0.9929\n",
            "Epoch 244/500\n",
            "86/86 [==============================] - 6s 64ms/step - loss: 0.0218 - accuracy: 0.9934\n",
            "Epoch 245/500\n",
            "86/86 [==============================] - 5s 64ms/step - loss: 0.0217 - accuracy: 0.9935\n",
            "Epoch 246/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0234 - accuracy: 0.9929\n",
            "Epoch 247/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0221 - accuracy: 0.9933\n",
            "Epoch 248/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0226 - accuracy: 0.9931\n",
            "Epoch 249/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0226 - accuracy: 0.9933\n",
            "Epoch 250/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0226 - accuracy: 0.9932\n",
            "Epoch 251/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0228 - accuracy: 0.9931\n",
            "Epoch 252/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0229 - accuracy: 0.9932\n",
            "Epoch 253/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0215 - accuracy: 0.9936\n",
            "Epoch 254/500\n",
            "86/86 [==============================] - 5s 61ms/step - loss: 0.0193 - accuracy: 0.9942\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: (5_enc,3_layer,1024_800_128_units)augmented_s2s_stacked/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: (5_enc,3_layer,1024_800_128_units)augmented_s2s_stacked/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 255/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0231 - accuracy: 0.9930\n",
            "Epoch 256/500\n",
            "86/86 [==============================] - 6s 64ms/step - loss: 0.0225 - accuracy: 0.9932\n",
            "Epoch 257/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0222 - accuracy: 0.9933\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: (5_enc,3_layer,1024_800_128_units)augmented_s2s_stacked/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: (5_enc,3_layer,1024_800_128_units)augmented_s2s_stacked/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 258/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0232 - accuracy: 0.9930\n",
            "Epoch 259/500\n",
            "86/86 [==============================] - 5s 64ms/step - loss: 0.0226 - accuracy: 0.9932\n",
            "Epoch 260/500\n",
            "86/86 [==============================] - 5s 64ms/step - loss: 0.0223 - accuracy: 0.9933\n",
            "Epoch 261/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0209 - accuracy: 0.9934\n",
            "Epoch 262/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0232 - accuracy: 0.9932\n",
            "Epoch 263/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0224 - accuracy: 0.9932\n",
            "Epoch 264/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0222 - accuracy: 0.9933\n",
            "Epoch 265/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0200 - accuracy: 0.9939\n",
            "Epoch 266/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0220 - accuracy: 0.9933\n",
            "Epoch 267/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0214 - accuracy: 0.9935\n",
            "Epoch 268/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0234 - accuracy: 0.9931\n",
            "Epoch 269/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0235 - accuracy: 0.9928\n",
            "Epoch 270/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0224 - accuracy: 0.9933\n",
            "Epoch 271/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0218 - accuracy: 0.9934\n",
            "Epoch 272/500\n",
            "86/86 [==============================] - 5s 61ms/step - loss: 0.0207 - accuracy: 0.9939\n",
            "Epoch 273/500\n",
            "86/86 [==============================] - 5s 61ms/step - loss: 0.0221 - accuracy: 0.9932\n",
            "Epoch 274/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0205 - accuracy: 0.9937\n",
            "Epoch 275/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0205 - accuracy: 0.9936\n",
            "Epoch 276/500\n",
            "86/86 [==============================] - 5s 64ms/step - loss: 0.0215 - accuracy: 0.9936\n",
            "Epoch 277/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0224 - accuracy: 0.9936\n",
            "Epoch 278/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0213 - accuracy: 0.9936\n",
            "Epoch 279/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0212 - accuracy: 0.9937\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: (5_enc,3_layer,1024_800_128_units)augmented_s2s_stacked/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: (5_enc,3_layer,1024_800_128_units)augmented_s2s_stacked/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 280/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0222 - accuracy: 0.9934\n",
            "Epoch 281/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0232 - accuracy: 0.9931\n",
            "Epoch 282/500\n",
            "86/86 [==============================] - 6s 64ms/step - loss: 0.0239 - accuracy: 0.9929\n",
            "Epoch 283/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0209 - accuracy: 0.9938\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: (5_enc,3_layer,1024_800_128_units)augmented_s2s_stacked/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: (5_enc,3_layer,1024_800_128_units)augmented_s2s_stacked/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 284/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0203 - accuracy: 0.9939\n",
            "Epoch 285/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0192 - accuracy: 0.9940\n",
            "Epoch 286/500\n",
            "86/86 [==============================] - 6s 64ms/step - loss: 0.0203 - accuracy: 0.9940\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: (5_enc,3_layer,1024_800_128_units)augmented_s2s_stacked/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: (5_enc,3_layer,1024_800_128_units)augmented_s2s_stacked/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 287/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0227 - accuracy: 0.9931\n",
            "Epoch 288/500\n",
            "86/86 [==============================] - 6s 64ms/step - loss: 0.0204 - accuracy: 0.9937\n",
            "Epoch 289/500\n",
            "86/86 [==============================] - 6s 64ms/step - loss: 0.0219 - accuracy: 0.9934\n",
            "Epoch 290/500\n",
            "86/86 [==============================] - 5s 64ms/step - loss: 0.0215 - accuracy: 0.9935\n",
            "Epoch 291/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0215 - accuracy: 0.9937\n",
            "Epoch 292/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0195 - accuracy: 0.9939\n",
            "Epoch 293/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0211 - accuracy: 0.9936\n",
            "Epoch 294/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0216 - accuracy: 0.9935\n",
            "Epoch 295/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0192 - accuracy: 0.9943\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: (5_enc,3_layer,1024_800_128_units)augmented_s2s_stacked/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: (5_enc,3_layer,1024_800_128_units)augmented_s2s_stacked/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 296/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0223 - accuracy: 0.9932\n",
            "Epoch 297/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0203 - accuracy: 0.9937\n",
            "Epoch 298/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0218 - accuracy: 0.9934\n",
            "Epoch 299/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0204 - accuracy: 0.9938\n",
            "Epoch 300/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0204 - accuracy: 0.9939\n",
            "Epoch 301/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0210 - accuracy: 0.9935\n",
            "Epoch 302/500\n",
            "86/86 [==============================] - 5s 64ms/step - loss: 0.0206 - accuracy: 0.9936\n",
            "Epoch 303/500\n",
            "86/86 [==============================] - 5s 64ms/step - loss: 0.0210 - accuracy: 0.9934\n",
            "Epoch 304/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0208 - accuracy: 0.9939\n",
            "Epoch 305/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0199 - accuracy: 0.9939\n",
            "Epoch 306/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0227 - accuracy: 0.9931\n",
            "Epoch 307/500\n",
            "86/86 [==============================] - 5s 61ms/step - loss: 0.0201 - accuracy: 0.9940\n",
            "Epoch 308/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0214 - accuracy: 0.9935\n",
            "Epoch 309/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0207 - accuracy: 0.9937\n",
            "Epoch 310/500\n",
            "86/86 [==============================] - 5s 61ms/step - loss: 0.0215 - accuracy: 0.9934\n",
            "Epoch 311/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0220 - accuracy: 0.9934\n",
            "Epoch 312/500\n",
            "86/86 [==============================] - 5s 61ms/step - loss: 0.0205 - accuracy: 0.9935\n",
            "Epoch 313/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0219 - accuracy: 0.9935\n",
            "Epoch 314/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0211 - accuracy: 0.9936\n",
            "Epoch 315/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0201 - accuracy: 0.9937\n",
            "Epoch 316/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0220 - accuracy: 0.9932\n",
            "Epoch 317/500\n",
            "86/86 [==============================] - 5s 64ms/step - loss: 0.0220 - accuracy: 0.9932\n",
            "Epoch 318/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0197 - accuracy: 0.9939\n",
            "Epoch 319/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0210 - accuracy: 0.9935\n",
            "Epoch 320/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0213 - accuracy: 0.9937\n",
            "Epoch 321/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0207 - accuracy: 0.9937\n",
            "Epoch 322/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0209 - accuracy: 0.9938\n",
            "Epoch 323/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0217 - accuracy: 0.9935\n",
            "Epoch 324/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0213 - accuracy: 0.9935\n",
            "Epoch 325/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0218 - accuracy: 0.9936\n",
            "Epoch 326/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0201 - accuracy: 0.9943\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: (5_enc,3_layer,1024_800_128_units)augmented_s2s_stacked/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: (5_enc,3_layer,1024_800_128_units)augmented_s2s_stacked/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 327/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0209 - accuracy: 0.9935\n",
            "Epoch 328/500\n",
            "86/86 [==============================] - 5s 64ms/step - loss: 0.0209 - accuracy: 0.9935\n",
            "Epoch 329/500\n",
            "86/86 [==============================] - 5s 64ms/step - loss: 0.0216 - accuracy: 0.9934\n",
            "Epoch 330/500\n",
            "86/86 [==============================] - 5s 64ms/step - loss: 0.0211 - accuracy: 0.9935\n",
            "Epoch 331/500\n",
            "86/86 [==============================] - 5s 64ms/step - loss: 0.0199 - accuracy: 0.9939\n",
            "Epoch 332/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0210 - accuracy: 0.9939\n",
            "Epoch 333/500\n",
            "86/86 [==============================] - 5s 64ms/step - loss: 0.0192 - accuracy: 0.9944\n",
            "Epoch 334/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0216 - accuracy: 0.9933\n",
            "Epoch 335/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0199 - accuracy: 0.9940\n",
            "Epoch 336/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0198 - accuracy: 0.9939\n",
            "Epoch 337/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0218 - accuracy: 0.9933\n",
            "Epoch 338/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0197 - accuracy: 0.9939\n",
            "Epoch 339/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0219 - accuracy: 0.9933\n",
            "Epoch 340/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0200 - accuracy: 0.9939\n",
            "Epoch 341/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0199 - accuracy: 0.9941\n",
            "Epoch 342/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0200 - accuracy: 0.9939\n",
            "Epoch 343/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0199 - accuracy: 0.9938\n",
            "Epoch 344/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0200 - accuracy: 0.9941\n",
            "Epoch 345/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0202 - accuracy: 0.9939\n",
            "Epoch 346/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0209 - accuracy: 0.9936\n",
            "Epoch 347/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0187 - accuracy: 0.9943\n",
            "Epoch 348/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0196 - accuracy: 0.9942\n",
            "Epoch 349/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0203 - accuracy: 0.9938\n",
            "Epoch 350/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0193 - accuracy: 0.9941\n",
            "Epoch 351/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0191 - accuracy: 0.9941\n",
            "Epoch 352/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0190 - accuracy: 0.9940\n",
            "Epoch 353/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0188 - accuracy: 0.9942\n",
            "Epoch 354/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0197 - accuracy: 0.9938\n",
            "Epoch 355/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0202 - accuracy: 0.9938\n",
            "Epoch 356/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0206 - accuracy: 0.9936\n",
            "Epoch 357/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0199 - accuracy: 0.9938\n",
            "Epoch 358/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0212 - accuracy: 0.9937\n",
            "Epoch 359/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0191 - accuracy: 0.9940\n",
            "Epoch 360/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0181 - accuracy: 0.9945\n",
            "Epoch 361/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0226 - accuracy: 0.9930\n",
            "Epoch 362/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0180 - accuracy: 0.9945\n",
            "Epoch 363/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0195 - accuracy: 0.9941\n",
            "Epoch 364/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0208 - accuracy: 0.9938\n",
            "Epoch 365/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0195 - accuracy: 0.9940\n",
            "Epoch 366/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0193 - accuracy: 0.9940\n",
            "Epoch 367/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0187 - accuracy: 0.9942\n",
            "Epoch 368/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0198 - accuracy: 0.9939\n",
            "Epoch 369/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0191 - accuracy: 0.9941\n",
            "Epoch 370/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0189 - accuracy: 0.9943\n",
            "Epoch 371/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0207 - accuracy: 0.9937\n",
            "Epoch 372/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0202 - accuracy: 0.9935\n",
            "Epoch 373/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0191 - accuracy: 0.9939\n",
            "Epoch 374/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0206 - accuracy: 0.9937\n",
            "Epoch 375/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0197 - accuracy: 0.9939\n",
            "Epoch 376/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0216 - accuracy: 0.9933\n",
            "Epoch 377/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0196 - accuracy: 0.9940\n",
            "Epoch 378/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0218 - accuracy: 0.9932\n",
            "Epoch 379/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0197 - accuracy: 0.9941\n",
            "Epoch 380/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0192 - accuracy: 0.9939\n",
            "Epoch 381/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0189 - accuracy: 0.9942\n",
            "Epoch 382/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0203 - accuracy: 0.9939\n",
            "Epoch 383/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0201 - accuracy: 0.9940\n",
            "Epoch 384/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0202 - accuracy: 0.9938\n",
            "Epoch 385/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0211 - accuracy: 0.9932\n",
            "Epoch 386/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0198 - accuracy: 0.9938\n",
            "Epoch 387/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0203 - accuracy: 0.9938\n",
            "Epoch 388/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0188 - accuracy: 0.9939\n",
            "Epoch 389/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0195 - accuracy: 0.9939\n",
            "Epoch 390/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0203 - accuracy: 0.9936\n",
            "Epoch 391/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0203 - accuracy: 0.9936\n",
            "Epoch 392/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0185 - accuracy: 0.9944\n",
            "Epoch 393/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0211 - accuracy: 0.9936\n",
            "Epoch 394/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0182 - accuracy: 0.9945\n",
            "Epoch 395/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0210 - accuracy: 0.9936\n",
            "Epoch 396/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0195 - accuracy: 0.9938\n",
            "Epoch 397/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0203 - accuracy: 0.9937\n",
            "Epoch 398/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0199 - accuracy: 0.9941\n",
            "Epoch 399/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0195 - accuracy: 0.9940\n",
            "Epoch 400/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0187 - accuracy: 0.9942\n",
            "Epoch 401/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0198 - accuracy: 0.9939\n",
            "Epoch 402/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0196 - accuracy: 0.9938\n",
            "Epoch 403/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0201 - accuracy: 0.9940\n",
            "Epoch 404/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0178 - accuracy: 0.9943\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: (5_enc,3_layer,1024_800_128_units)augmented_s2s_stacked/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: (5_enc,3_layer,1024_800_128_units)augmented_s2s_stacked/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 405/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0192 - accuracy: 0.9941\n",
            "Epoch 406/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0183 - accuracy: 0.9942\n",
            "Epoch 407/500\n",
            "86/86 [==============================] - 5s 64ms/step - loss: 0.0196 - accuracy: 0.9937\n",
            "Epoch 408/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0193 - accuracy: 0.9940\n",
            "Epoch 409/500\n",
            "86/86 [==============================] - 5s 64ms/step - loss: 0.0183 - accuracy: 0.9941\n",
            "Epoch 410/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0200 - accuracy: 0.9940\n",
            "Epoch 411/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0179 - accuracy: 0.9945\n",
            "Epoch 412/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0177 - accuracy: 0.9944\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: (5_enc,3_layer,1024_800_128_units)augmented_s2s_stacked/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: (5_enc,3_layer,1024_800_128_units)augmented_s2s_stacked/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 413/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0192 - accuracy: 0.9941\n",
            "Epoch 414/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0185 - accuracy: 0.9940\n",
            "Epoch 415/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0189 - accuracy: 0.9939\n",
            "Epoch 416/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0200 - accuracy: 0.9937\n",
            "Epoch 417/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0196 - accuracy: 0.9939\n",
            "Epoch 418/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0185 - accuracy: 0.9942\n",
            "Epoch 419/500\n",
            "86/86 [==============================] - 5s 64ms/step - loss: 0.0188 - accuracy: 0.9942\n",
            "Epoch 420/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0193 - accuracy: 0.9940\n",
            "Epoch 421/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0174 - accuracy: 0.9944\n",
            "Epoch 422/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0192 - accuracy: 0.9939\n",
            "Epoch 423/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0181 - accuracy: 0.9945\n",
            "Epoch 424/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0172 - accuracy: 0.9947\n",
            "Epoch 425/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0184 - accuracy: 0.9943\n",
            "Epoch 426/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0203 - accuracy: 0.9937\n",
            "Epoch 427/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0190 - accuracy: 0.9941\n",
            "Epoch 428/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0185 - accuracy: 0.9943\n",
            "Epoch 429/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0186 - accuracy: 0.9943\n",
            "Epoch 430/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0180 - accuracy: 0.9943\n",
            "Epoch 431/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0187 - accuracy: 0.9943\n",
            "Epoch 432/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0181 - accuracy: 0.9943\n",
            "Epoch 433/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0196 - accuracy: 0.9941\n",
            "Epoch 434/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0194 - accuracy: 0.9939\n",
            "Epoch 435/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0182 - accuracy: 0.9942\n",
            "Epoch 436/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0186 - accuracy: 0.9942\n",
            "Epoch 437/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0194 - accuracy: 0.9938\n",
            "Epoch 438/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0192 - accuracy: 0.9937\n",
            "Epoch 439/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0178 - accuracy: 0.9946\n",
            "Epoch 440/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0199 - accuracy: 0.9939\n",
            "Epoch 441/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0179 - accuracy: 0.9944\n",
            "Epoch 442/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0195 - accuracy: 0.9940\n",
            "Epoch 443/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0196 - accuracy: 0.9936\n",
            "Epoch 444/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0186 - accuracy: 0.9942\n",
            "Epoch 445/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0170 - accuracy: 0.9946\n",
            "Epoch 446/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0192 - accuracy: 0.9941\n",
            "Epoch 447/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0181 - accuracy: 0.9944\n",
            "Epoch 448/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0185 - accuracy: 0.9941\n",
            "Epoch 449/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0172 - accuracy: 0.9945\n",
            "Epoch 450/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0174 - accuracy: 0.9946\n",
            "Epoch 451/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0195 - accuracy: 0.9941\n",
            "Epoch 452/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0195 - accuracy: 0.9940\n",
            "Epoch 453/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0184 - accuracy: 0.9942\n",
            "Epoch 454/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0183 - accuracy: 0.9942\n",
            "Epoch 455/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0180 - accuracy: 0.9944\n",
            "Epoch 456/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0190 - accuracy: 0.9939\n",
            "Epoch 457/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0188 - accuracy: 0.9942\n",
            "Epoch 458/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0174 - accuracy: 0.9943\n",
            "Epoch 459/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0197 - accuracy: 0.9936\n",
            "Epoch 460/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0183 - accuracy: 0.9943\n",
            "Epoch 461/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0183 - accuracy: 0.9941\n",
            "Epoch 462/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0190 - accuracy: 0.9941\n",
            "Epoch 463/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0179 - accuracy: 0.9947\n",
            "Epoch 464/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0186 - accuracy: 0.9942\n",
            "Epoch 465/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0168 - accuracy: 0.9946\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: (5_enc,3_layer,1024_800_128_units)augmented_s2s_stacked/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: (5_enc,3_layer,1024_800_128_units)augmented_s2s_stacked/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 466/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0182 - accuracy: 0.9941\n",
            "Epoch 467/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0180 - accuracy: 0.9946\n",
            "Epoch 468/500\n",
            "86/86 [==============================] - 5s 64ms/step - loss: 0.0182 - accuracy: 0.9943\n",
            "Epoch 469/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0168 - accuracy: 0.9946\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_3_layer_call_and_return_conditional_losses, lstm_cell_3_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: (5_enc,3_layer,1024_800_128_units)augmented_s2s_stacked/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: (5_enc,3_layer,1024_800_128_units)augmented_s2s_stacked/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 470/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0192 - accuracy: 0.9942\n",
            "Epoch 471/500\n",
            "86/86 [==============================] - 5s 64ms/step - loss: 0.0183 - accuracy: 0.9941\n",
            "Epoch 472/500\n",
            "86/86 [==============================] - 6s 65ms/step - loss: 0.0168 - accuracy: 0.9945\n",
            "Epoch 473/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0181 - accuracy: 0.9942\n",
            "Epoch 474/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0180 - accuracy: 0.9945\n",
            "Epoch 475/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0176 - accuracy: 0.9946\n",
            "Epoch 476/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0190 - accuracy: 0.9940\n",
            "Epoch 477/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0196 - accuracy: 0.9938\n",
            "Epoch 478/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0166 - accuracy: 0.9947\n",
            "Epoch 479/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0184 - accuracy: 0.9943\n",
            "Epoch 480/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0167 - accuracy: 0.9948\n",
            "Epoch 481/500\n",
            "86/86 [==============================] - 5s 61ms/step - loss: 0.0189 - accuracy: 0.9940\n",
            "Epoch 482/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0192 - accuracy: 0.9942\n",
            "Epoch 483/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0178 - accuracy: 0.9943\n",
            "Epoch 484/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0191 - accuracy: 0.9939\n",
            "Epoch 485/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0167 - accuracy: 0.9948\n",
            "Epoch 486/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0186 - accuracy: 0.9942\n",
            "Epoch 487/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0183 - accuracy: 0.9942\n",
            "Epoch 488/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0204 - accuracy: 0.9936\n",
            "Epoch 489/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0190 - accuracy: 0.9940\n",
            "Epoch 490/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0187 - accuracy: 0.9942\n",
            "Epoch 491/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0171 - accuracy: 0.9946\n",
            "Epoch 492/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0172 - accuracy: 0.9944\n",
            "Epoch 493/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0181 - accuracy: 0.9946\n",
            "Epoch 494/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0183 - accuracy: 0.9944\n",
            "Epoch 495/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0176 - accuracy: 0.9944\n",
            "Epoch 496/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0187 - accuracy: 0.9942\n",
            "Epoch 497/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0206 - accuracy: 0.9938\n",
            "Epoch 498/500\n",
            "86/86 [==============================] - 5s 62ms/step - loss: 0.0170 - accuracy: 0.9946\n",
            "Epoch 499/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0185 - accuracy: 0.9942\n",
            "Epoch 500/500\n",
            "86/86 [==============================] - 5s 63ms/step - loss: 0.0189 - accuracy: 0.9941\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "id": "j8trgBwdOiOv",
        "outputId": "9bd78673-c82f-4dd1-f27b-47c96fb018ba"
      },
      "source": [
        "max_acc = max(history.history['accuracy'])\n",
        "max_acc_idx = np.argmax(history.history['accuracy'])\n",
        "print(\"Max Accuracy\", max_acc, \" at epoch:\", max_acc_idx+1)\n",
        "\n",
        "pyplot.plot(history.history['loss'])\n",
        "pyplot.show()\n",
        "pyplot.plot(history.history['accuracy'])\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-7d8871f5db3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmax_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmax_acc_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Max Accuracy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" at epoch:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_acc_idx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjhFl6Kl929t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "1339f34c-c506-4748-a88a-aa3353352a2e"
      },
      "source": [
        "# plot_history(history)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-a8489d1127d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-29-97ffdeaf0131>\u001b[0m in \u001b[0;36mplot_history\u001b[0;34m(history)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmax_val_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mmax_val_acc_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Max Validation Accuracy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_val_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" at epoch:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_val_acc_idx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" with Training Accuracy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmax_val_acc_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'val_accuracy'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lC-6iZOkhX8-"
      },
      "source": [
        "# Inference mode"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvkl-Ng3u_xm"
      },
      "source": [
        "def get_inference_model(model):\n",
        "    # define inference encoder\n",
        "    encoder_inputs = model.input[0]\n",
        "    encoder_states = []\n",
        "    for i in range(1, len(n_units)+1):\n",
        "        encoder_states += model.get_layer(f'encoder_lstm_{i}').output[1:]\n",
        "    infer_encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "\n",
        "    # define inference decoder\n",
        "    decoder_inputs = model.input[1]\n",
        "    decoder_outputs = decoder_inputs\n",
        "    decoder_states_inputs = []\n",
        "    decoder_states = []\n",
        "    for j in range(len(n_units))[::-1]:\n",
        "        current_state_inputs = [Input(shape=(n_units[j],)) for _ in range(2)]\n",
        "        temp = model.get_layer(f'decoder_lstm_{len(n_units)-j}')(decoder_outputs, initial_state=current_state_inputs)\n",
        "        decoder_outputs, curr_states = temp[0], temp[1:]\n",
        "\n",
        "        decoder_states += curr_states\n",
        "        decoder_states_inputs += current_state_inputs\n",
        "\n",
        "    decoder_dense = model.get_layer('decoder_dense')\n",
        "    decoder_outputs = decoder_dense(decoder_outputs)\n",
        "    infer_decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states, name=\"augmented_s2s_model\")\n",
        "    \n",
        "    return infer_encoder_model, infer_decoder_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JDB4en6vTpc"
      },
      "source": [
        "def decode_sequence(infer_encoder_model, infer_decoder_model, input_seq, actual_target_sequence):\n",
        "    # print(np.count_nonzero(actual_target_sequence))\n",
        "    # if np.count_nonzero(actual_target_sequence) != 5:\n",
        "    #     return -1\n",
        "\n",
        "    input_seq_oh = tf.one_hot(input_seq, num_encoder_tokens+1, dtype='int32').numpy()\n",
        "\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1, 1, num_decoder_tokens+1))\n",
        "    # Populate the first character of target sequence with the start character <sos>\n",
        "    target_seq[0, 0, decoder_word2idx['<sos>']] = 1\n",
        "\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = infer_encoder_model.predict(input_seq_oh)\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sequence = []\n",
        "    # print(\"Actual Input Sequence:\", input_seq)\n",
        "    # print(\"Text:\", convert_to_seq(input_seq[0], encoder_idx2word), \"\\n\")\n",
        "    # print(\"Actual Target Sequence:\", actual_target_sequence)\n",
        "    # print(\"Text:\", convert_to_seq(actual_target_sequence, decoder_idx2word), \"\\n\")\n",
        "    idx = 0\n",
        "\n",
        "    while not stop_condition:\n",
        "        #print(target_seq)\n",
        "        # output_tokens, h, c = infer_decoder_model.predict([target_seq] + states_value)\n",
        "        to_split = infer_decoder_model.predict([target_seq] + states_value)\n",
        "        output_tokens, states_value = to_split[0], to_split[1:]\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, 0])\n",
        "        decoded_sequence.append(sampled_token_index)\n",
        "        #sampled_step = decoder_idx2word[sampled_token_index]\n",
        "        \n",
        "        # Exit condition: either hit max length\n",
        "        # or find stop character <eos>\n",
        "        if actual_target_sequence[idx] == decoder_word2idx['<eos>']:\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1)\n",
        "        target_seq = np.zeros((1, 1, num_decoder_tokens+1))\n",
        "        # print(\"actual:\", actual_target_sequence[idx])\n",
        "        # print(\"predicted:\", sampled_token_index)\n",
        "        if sampled_token_index == actual_target_sequence[idx]:\n",
        "            # print(\"match\")\n",
        "            target_seq[0, 0, sampled_token_index] = 1\n",
        "        else:\n",
        "            target_seq[0, 0, actual_target_sequence[idx]] = 1 # feed in the actual step in case of wrong prediction\n",
        "        \n",
        "        # Update states\n",
        "        # states_value = [h, c]\n",
        "        idx += 1\n",
        "\n",
        "    # print(\"Predicted Sequence:\", decoded_sequence)\n",
        "    # print(\"Text:\", convert_to_seq(decoded_sequence, decoder_idx2word), \"\\n\")\n",
        "    return decoded_sequence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GY1hqpBIKCWE"
      },
      "source": [
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNUlW3r7vX2Q"
      },
      "source": [
        "def predict(infer_encoder_model, infer_decoder_model, encoder_test_input, decoder_test_target): \n",
        "    predicted_sequences = []\n",
        "    correct_steps = []\n",
        "    total_step_count = 0\n",
        "    accurate_prediction_count = 0\n",
        "\n",
        "    num_test_samples = len(encoder_test_input)\n",
        "    for i in tqdm(range(num_test_samples)):\n",
        "    # for i in range(num_test_samples):\n",
        "        input_seq = encoder_test_input[i:i+1]\n",
        "        decoded_sequence = decode_sequence(infer_encoder_model, infer_decoder_model, input_seq, decoder_test_target[i])\n",
        "\n",
        "        correct_steps = [i for i, j in zip(decoder_test_target[i], decoded_sequence) if i == j]\n",
        "        curr_acc_pred_cnt = len(correct_steps)\n",
        "        accurate_prediction_count += curr_acc_pred_cnt\n",
        "        total_step_count += len(decoded_sequence)\n",
        "        # print(curr_acc_pred_cnt, \" out of \",  len(decoded_sequence),\" step(s) correctly predicted\")\n",
        "\n",
        "        predicted_sequences.append(decoded_sequence)\n",
        "        # print()\n",
        "\n",
        "    print(\"\\nTotal Predicted Steps:\", total_step_count)\n",
        "    print(\"Total Accurate Prediction:\", accurate_prediction_count)\n",
        "\n",
        "    return predicted_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4rmLTDLrPRu"
      },
      "source": [
        "def convert_to_seq(seq, idx2word):\n",
        "# seq = [30, 30, 3, 8, 18]\n",
        "    attack_sequence = []\n",
        "    for step_idx in seq:\n",
        "        if step_idx == 0:\n",
        "            break\n",
        "        attack_sequence.append(idx2word[step_idx])\n",
        "    return attack_sequence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GrLyN9O5DyN"
      },
      "source": [
        "from tensorflow.keras import models\n",
        "model = models.load_model(\"(5_enc,3_layer,1024_800_128_units)augmented_s2s_stacked\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JZiTkL1vbGM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6dcab1f-5bd6-4f90-a859-24808c070924"
      },
      "source": [
        "infer_encoder_model, infer_decoder_model = get_inference_model(model)\n",
        "infer_decoder_model.summary()\n",
        "predicted_sequences = predict(infer_encoder_model, infer_decoder_model, encoder_test_input, decoder_test_target)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1367 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"augmented_s2s_model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "decoder_input (InputLayer)      [(None, None, 53)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_1 (InputLayer)            [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "decoder_lstm_1 (LSTM)           [(None, None, 128),  93184       decoder_input[0][0]              \n",
            "                                                                 input_1[0][0]                    \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, 800)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            [(None, 800)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "decoder_lstm_2 (LSTM)           [(None, None, 800),  2972800     decoder_lstm_1[1][0]             \n",
            "                                                                 input_3[0][0]                    \n",
            "                                                                 input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_5 (InputLayer)            [(None, 1024)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_6 (InputLayer)            [(None, 1024)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "decoder_lstm_3 (LSTM)           [(None, None, 1024), 7475200     decoder_lstm_2[1][0]             \n",
            "                                                                 input_5[0][0]                    \n",
            "                                                                 input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "decoder_dense (Dense)           (None, None, 53)     54325       decoder_lstm_3[1][0]             \n",
            "==================================================================================================\n",
            "Total params: 10,595,509\n",
            "Trainable params: 10,595,509\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1367/1367 [10:14<00:00,  2.22it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Total Predicted Steps: 11583\n",
            "Total Accurate Prediction: 10088\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}